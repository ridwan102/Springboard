{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A0TQHyu8cAU0"
   },
   "source": [
    "# Springboard Data Science Career Track Unit 4 Challenge - Tier Two Complete\n",
    "\n",
    "## Objectives\n",
    "Hey! Great job getting through those challenging DataCamp courses. You're learning a lot in a short span of time. Let's see how this new knowledge can help solve a real world problem. \n",
    "\n",
    "In this notebook, we're going to apply the skills you've been learning, bridging the gap between the controlled environment of DataCamp and the *slightly* messier work that data scientists do with actual datasets!\n",
    "\n",
    "Here’s the mystery we’re going to solve: ***which boroughs of London have seen the greatest increase in housing prices, on average, over the last two decades?***\n",
    "\n",
    "\n",
    "A borough is just a fancy word for district. You may be familiar with the five boroughs of New York… well, there are 32 boroughs within Greater London [(here's some info for the curious)](https://en.wikipedia.org/wiki/London_boroughs). Some of them are more desirable areas to live in, and the data will reflect that with a greater rise in housing prices.\n",
    "\n",
    "This is the Tier Two notebook. Don't sweat it if you got stuck on the highest difficulty. You'll have a lot more guidance this time around. If you get stuck again, you can always drop down to Tier One. Just remember to come back around and redo the project on the higher difficulty.\n",
    "\n",
    "This challenge will make use of only what you learned in the following DataCamp courses: \n",
    "- Prework courses (Introduction to Python for Data Science, Intermediate Python for Data Science)\n",
    "- Data Types for Data Science\n",
    "- Python Data Science Toolbox (Part One) \n",
    "- pandas Foundations\n",
    "- Manipulating DataFrames with pandas\n",
    "- Merging DataFrames with pandas\n",
    "\n",
    "Of the tools, techniques and concepts in the above DataCamp courses, this challenge should require the application of the following: \n",
    "- **pandas**\n",
    "    - **data ingestion and inspection** (pandas Foundations, Module One) \n",
    "    - **exploratory data analysis** (pandas Foundations, Module Two)\n",
    "    - **tidying and cleaning** (Manipulating DataFrames with pandas, Module Three) \n",
    "    - **transforming DataFrames** (Manipulating DataFrames with pandas, Module One)\n",
    "    - **subsetting DataFrames with lists** (Manipulating DataFrames with pandas, Module One) \n",
    "    - **filtering DataFrames** (Manipulating DataFrames with pandas, Module One) \n",
    "    - **grouping data** (Manipulating DataFrames with pandas, Module Four) \n",
    "    - **melting data** (Manipulating DataFrames with pandas, Module Three) \n",
    "    - **advanced indexing** (Manipulating DataFrames with pandas, Module Four) \n",
    "- **matplotlib** (Intermediate Python for Data Science, Module One)\n",
    "- **fundamental data types** (Data Types for Data Science, Module One) \n",
    "- **dictionaries** (Intermediate Python for Data Science, Module Two)\n",
    "- **handling dates and times** (Data Types for Data Science, Module Four)\n",
    "- **function definition** (Python Data Science Toolbox - Part One, Module One)\n",
    "- **default arguments, variable length, and scope** (Python Data Science Toolbox - Part One, Module Two) \n",
    "- **lambda functions and error handling** (Python Data Science Toolbox - Part One, Module Four) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IzUYCh-EcAU2"
   },
   "source": [
    "## The Data Science Pipeline\n",
    "Data Science is magical. In this case study, you'll get to apply some complex machine learning algorithms. But as  [David Spiegelhalter](https://www.youtube.com/watch?v=oUs1uvsz0Ok) reminds us, there is no substitute for simply **taking a really, really good look at the data.** Sometimes, this is all we need to answer our question.\n",
    "\n",
    "Data Science projects generally adhere to the four stages of Data Science Pipeline:\n",
    "1. Sourcing and loading \n",
    "2. Cleaning, transforming, and visualizing \n",
    "3. Modeling \n",
    "4. Evaluating and concluding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u8vWP1fccAU3"
   },
   "source": [
    "### 1. Sourcing and Loading \n",
    "\n",
    "Any Data Science project kicks off by importing  ***pandas***. The documentation of this wonderful library can be found [here](https://pandas.pydata.org/). As you've seen, pandas is conveniently connected to the [Numpy](http://www.numpy.org/) and [Matplotlib](https://matplotlib.org/) libraries. \n",
    "\n",
    "***Hint:*** This part of the data science pipeline will test those skills you acquired in the pandas Foundations course, Module One. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Eni457VLcAU4"
   },
   "source": [
    "#### 1.1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S1MNvAo4cAU4"
   },
   "outputs": [],
   "source": [
    "# Let's import the pandas, numpy libraries as pd, and np respectively. \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "# Load the pyplot collection of functions from matplotlib, as plt \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nXaI_sTJcAU7"
   },
   "source": [
    "#### 1.2.  Loading the data\n",
    "\n",
    "\n",
    "Your data comes from the [London Datastore](https://data.london.gov.uk/): a free, open-source data-sharing portal for London-oriented datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yQaBWqficAU8"
   },
   "outputs": [],
   "source": [
    "# First, make a variable called url_LondonHousePrices, and assign it the following link, enclosed in quotation-marks as a string:\n",
    "# https://data.london.gov.uk/download/uk-house-price-index/70ac0766-8902-4eb5-aab5-01951aaed773/UK%20House%20price%20index.xls\n",
    "\n",
    "url_LondonHousePrices = \"https://data.london.gov.uk/download/uk-house-price-index/70ac0766-8902-4eb5-aab5-01951aaed773/UK%20House%20price%20index.xls\"\n",
    "\n",
    "# The dataset we're interested in contains the Average prices of the houses, and is actually on a particular sheet of the Excel file. \n",
    "# As a result, we need to specify the sheet name in the read_excel() method.\n",
    "# Put this data into a variable called properties.  \n",
    "properties = pd.read_excel(url_LondonHousePrices, sheet_name='Average price', index_col= None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z7D2LXfMcAU-"
   },
   "source": [
    "### 2. Cleaning, transforming, and visualizing \n",
    "This second stage is arguably the most important part of any Data Science project. The first thing to do is take a proper look at the data. Cleaning forms the majority of this stage, and can be done both before or after Transformation.\n",
    "\n",
    "The end goal of data cleaning is to have tidy data. When data is tidy: \n",
    "\n",
    "1. Each variable has a column.\n",
    "2. Each observation forms a row.\n",
    "\n",
    "Keep the end goal in mind as you move through this process, every step will take you closer. \n",
    "\n",
    "\n",
    "\n",
    "***Hint:*** This part of the data science pipeline should test those skills you acquired in: \n",
    "- Intermediate Python for data science, all modules.\n",
    "- pandas Foundations, all modules. \n",
    "- Manipulating DataFrames with pandas, all modules.\n",
    "- Data Types for Data Science, Module Four.\n",
    "- Python Data Science Toolbox - Part One, all modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h4ta27NycAU_"
   },
   "source": [
    "#### 2.1. Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QXVWC7ZecAU_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(304, 49)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First off, let's use .shape feature of pandas DataFrames to look at the number of rows and columns. \n",
    "properties.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R04S1lGycAVB"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>City of London</th>\n",
       "      <th>Barking &amp; Dagenham</th>\n",
       "      <th>Barnet</th>\n",
       "      <th>Bexley</th>\n",
       "      <th>Brent</th>\n",
       "      <th>Bromley</th>\n",
       "      <th>Camden</th>\n",
       "      <th>Croydon</th>\n",
       "      <th>Ealing</th>\n",
       "      <th>...</th>\n",
       "      <th>NORTH WEST</th>\n",
       "      <th>YORKS &amp; THE HUMBER</th>\n",
       "      <th>EAST MIDLANDS</th>\n",
       "      <th>WEST MIDLANDS</th>\n",
       "      <th>EAST OF ENGLAND</th>\n",
       "      <th>LONDON</th>\n",
       "      <th>SOUTH EAST</th>\n",
       "      <th>SOUTH WEST</th>\n",
       "      <th>Unnamed: 47</th>\n",
       "      <th>England</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaT</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>E09000002</td>\n",
       "      <td>E09000003</td>\n",
       "      <td>E09000004</td>\n",
       "      <td>E09000005</td>\n",
       "      <td>E09000006</td>\n",
       "      <td>E09000007</td>\n",
       "      <td>E09000008</td>\n",
       "      <td>E09000009</td>\n",
       "      <td>...</td>\n",
       "      <td>E12000002</td>\n",
       "      <td>E12000003</td>\n",
       "      <td>E12000004</td>\n",
       "      <td>E12000005</td>\n",
       "      <td>E12000006</td>\n",
       "      <td>E12000007</td>\n",
       "      <td>E12000008</td>\n",
       "      <td>E12000009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E92000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>91449</td>\n",
       "      <td>50460.2</td>\n",
       "      <td>93284.5</td>\n",
       "      <td>64958.1</td>\n",
       "      <td>71306.6</td>\n",
       "      <td>81671.5</td>\n",
       "      <td>120933</td>\n",
       "      <td>69158.2</td>\n",
       "      <td>79885.9</td>\n",
       "      <td>...</td>\n",
       "      <td>43958.5</td>\n",
       "      <td>44803.4</td>\n",
       "      <td>45544.5</td>\n",
       "      <td>48527.5</td>\n",
       "      <td>56701.6</td>\n",
       "      <td>74435.8</td>\n",
       "      <td>64018.9</td>\n",
       "      <td>54705.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53202.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1995-02-01</td>\n",
       "      <td>82202.8</td>\n",
       "      <td>51085.8</td>\n",
       "      <td>93190.2</td>\n",
       "      <td>64787.9</td>\n",
       "      <td>72022.3</td>\n",
       "      <td>81657.6</td>\n",
       "      <td>119509</td>\n",
       "      <td>68951.1</td>\n",
       "      <td>80897.1</td>\n",
       "      <td>...</td>\n",
       "      <td>43925.4</td>\n",
       "      <td>44528.8</td>\n",
       "      <td>46051.6</td>\n",
       "      <td>49341.3</td>\n",
       "      <td>56593.6</td>\n",
       "      <td>72777.9</td>\n",
       "      <td>63715</td>\n",
       "      <td>54356.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53096.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1995-03-01</td>\n",
       "      <td>79120.7</td>\n",
       "      <td>51269</td>\n",
       "      <td>92247.5</td>\n",
       "      <td>64367.5</td>\n",
       "      <td>72015.8</td>\n",
       "      <td>81449.3</td>\n",
       "      <td>120282</td>\n",
       "      <td>68712.4</td>\n",
       "      <td>81379.9</td>\n",
       "      <td>...</td>\n",
       "      <td>44434.9</td>\n",
       "      <td>45200.5</td>\n",
       "      <td>45383.8</td>\n",
       "      <td>49442.2</td>\n",
       "      <td>56171.2</td>\n",
       "      <td>73896.8</td>\n",
       "      <td>64113.6</td>\n",
       "      <td>53583.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53201.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1995-04-01</td>\n",
       "      <td>77101.2</td>\n",
       "      <td>53133.5</td>\n",
       "      <td>90762.9</td>\n",
       "      <td>64277.7</td>\n",
       "      <td>72965.6</td>\n",
       "      <td>81124.4</td>\n",
       "      <td>120098</td>\n",
       "      <td>68610</td>\n",
       "      <td>82188.9</td>\n",
       "      <td>...</td>\n",
       "      <td>44267.8</td>\n",
       "      <td>45614.3</td>\n",
       "      <td>46124.2</td>\n",
       "      <td>49455.9</td>\n",
       "      <td>56567.9</td>\n",
       "      <td>74455.3</td>\n",
       "      <td>64623.2</td>\n",
       "      <td>54786</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53590.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0 City of London Barking & Dagenham     Barnet     Bexley  \\\n",
       "0        NaT      E09000001          E09000002  E09000003  E09000004   \n",
       "1 1995-01-01          91449            50460.2    93284.5    64958.1   \n",
       "2 1995-02-01        82202.8            51085.8    93190.2    64787.9   \n",
       "3 1995-03-01        79120.7              51269    92247.5    64367.5   \n",
       "4 1995-04-01        77101.2            53133.5    90762.9    64277.7   \n",
       "\n",
       "       Brent    Bromley     Camden    Croydon     Ealing  ... NORTH WEST  \\\n",
       "0  E09000005  E09000006  E09000007  E09000008  E09000009  ...  E12000002   \n",
       "1    71306.6    81671.5     120933    69158.2    79885.9  ...    43958.5   \n",
       "2    72022.3    81657.6     119509    68951.1    80897.1  ...    43925.4   \n",
       "3    72015.8    81449.3     120282    68712.4    81379.9  ...    44434.9   \n",
       "4    72965.6    81124.4     120098      68610    82188.9  ...    44267.8   \n",
       "\n",
       "  YORKS & THE HUMBER EAST MIDLANDS WEST MIDLANDS EAST OF ENGLAND     LONDON  \\\n",
       "0          E12000003     E12000004     E12000005       E12000006  E12000007   \n",
       "1            44803.4       45544.5       48527.5         56701.6    74435.8   \n",
       "2            44528.8       46051.6       49341.3         56593.6    72777.9   \n",
       "3            45200.5       45383.8       49442.2         56171.2    73896.8   \n",
       "4            45614.3       46124.2       49455.9         56567.9    74455.3   \n",
       "\n",
       "  SOUTH EAST SOUTH WEST Unnamed: 47    England  \n",
       "0  E12000008  E12000009         NaN  E92000001  \n",
       "1    64018.9    54705.2         NaN    53202.8  \n",
       "2      63715    54356.1         NaN    53096.2  \n",
       "3    64113.6    53583.1         NaN    53201.3  \n",
       "4    64623.2      54786         NaN    53590.9  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the .head() method, let's check out the state of our dataset.  \n",
    "properties.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-5ffSAxDcAVD"
   },
   "source": [
    "Oh no! What are you supposed to do with this?\n",
    "\n",
    "You've got the data, but it doesn't look tidy. At this stage, you'd struggle to perform analysis on it. It is normal for your initial data set to be formatted in a way that is not conducive to analysis. A big part of our job is fixing that.\n",
    "\n",
    "Best practice is for pandas DataFrames to contain the observations of interest as rows, and the features of those observations as columns. You want tidy DataFrames: whose rows are observations and whose columns are variables.\n",
    "\n",
    "Notice here that the column headings are the particular boroughs, which is our observation of interest. The first column contains datetime objects that capture a particular month and year, which is a variable. Most of the other cell-values are the average proprety values of the borough corresponding to that time stamp.\n",
    "\n",
    "Clearly, we need to roll our sleeves up and do some cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7_STF8sZcAVE"
   },
   "source": [
    "####  2.2. Cleaning the data (Part 1)\n",
    "Data cleaning has a bad rep, but remember what your momma told you: cleanliness is next to godliness. Data cleaning can be really satisfying and fun. In the dark ages of programming, data cleaning was a tedious and difficult ordeal. Nowadays, new and improved tools have simplified the process. Getting good at data cleaning opens up a world of possibilities for data scientists and programmers. \n",
    " \n",
    "The first operation you want to do on the dataset is called **transposition**. you *transpose* a table when you flip the columns into rows, and *vice versa*. \n",
    "\n",
    "If you transpose this DataFrame then the borough names will become the row indices, and the date time objects will become the column headers. Since your end goal is tidy data, where each row will represent a borough and each column will contain data about that borough at a certain point in time, transposing the table bring you closer to where you want to be.\n",
    "\n",
    "Python makes transposition simple.\n",
    "\n",
    "Each pandas DataFrame already has the *.T* attribute which is the transposed version of that DataFrame.\n",
    "\n",
    "Assign the transposed version of the original to a new variable and call it *properties_T*. \n",
    "\n",
    "Boom! You’ve got a transposed table to play with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MElF4IBacAVF"
   },
   "outputs": [],
   "source": [
    "# Do this here\n",
    "properties_T = properties.T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E10vl2gbcAVG"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>300</th>\n",
       "      <th>301</th>\n",
       "      <th>302</th>\n",
       "      <th>303</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <td>NaT</td>\n",
       "      <td>1995-01-01 00:00:00</td>\n",
       "      <td>1995-02-01 00:00:00</td>\n",
       "      <td>1995-03-01 00:00:00</td>\n",
       "      <td>1995-04-01 00:00:00</td>\n",
       "      <td>1995-05-01 00:00:00</td>\n",
       "      <td>1995-06-01 00:00:00</td>\n",
       "      <td>1995-07-01 00:00:00</td>\n",
       "      <td>1995-08-01 00:00:00</td>\n",
       "      <td>1995-09-01 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-06-01 00:00:00</td>\n",
       "      <td>2019-07-01 00:00:00</td>\n",
       "      <td>2019-08-01 00:00:00</td>\n",
       "      <td>2019-09-01 00:00:00</td>\n",
       "      <td>2019-10-01 00:00:00</td>\n",
       "      <td>2019-11-01 00:00:00</td>\n",
       "      <td>2019-12-01 00:00:00</td>\n",
       "      <td>2020-01-01 00:00:00</td>\n",
       "      <td>2020-02-01 00:00:00</td>\n",
       "      <td>2020-03-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City of London</th>\n",
       "      <td>E09000001</td>\n",
       "      <td>91449</td>\n",
       "      <td>82202.8</td>\n",
       "      <td>79120.7</td>\n",
       "      <td>77101.2</td>\n",
       "      <td>84409.1</td>\n",
       "      <td>94900.5</td>\n",
       "      <td>110128</td>\n",
       "      <td>112329</td>\n",
       "      <td>104473</td>\n",
       "      <td>...</td>\n",
       "      <td>761526</td>\n",
       "      <td>756407</td>\n",
       "      <td>813770</td>\n",
       "      <td>810455</td>\n",
       "      <td>826227</td>\n",
       "      <td>776894</td>\n",
       "      <td>737275</td>\n",
       "      <td>757377</td>\n",
       "      <td>765416</td>\n",
       "      <td>792583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barking &amp; Dagenham</th>\n",
       "      <td>E09000002</td>\n",
       "      <td>50460.2</td>\n",
       "      <td>51085.8</td>\n",
       "      <td>51269</td>\n",
       "      <td>53133.5</td>\n",
       "      <td>53042.2</td>\n",
       "      <td>53700.3</td>\n",
       "      <td>52113.1</td>\n",
       "      <td>52232.2</td>\n",
       "      <td>51471.6</td>\n",
       "      <td>...</td>\n",
       "      <td>293889</td>\n",
       "      <td>297426</td>\n",
       "      <td>299421</td>\n",
       "      <td>304778</td>\n",
       "      <td>304579</td>\n",
       "      <td>306390</td>\n",
       "      <td>301283</td>\n",
       "      <td>304187</td>\n",
       "      <td>304719</td>\n",
       "      <td>327136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barnet</th>\n",
       "      <td>E09000003</td>\n",
       "      <td>93284.5</td>\n",
       "      <td>93190.2</td>\n",
       "      <td>92247.5</td>\n",
       "      <td>90762.9</td>\n",
       "      <td>90258</td>\n",
       "      <td>90107.2</td>\n",
       "      <td>91441.2</td>\n",
       "      <td>92361.3</td>\n",
       "      <td>93273.1</td>\n",
       "      <td>...</td>\n",
       "      <td>512694</td>\n",
       "      <td>514668</td>\n",
       "      <td>528577</td>\n",
       "      <td>526670</td>\n",
       "      <td>525678</td>\n",
       "      <td>522639</td>\n",
       "      <td>519306</td>\n",
       "      <td>520115</td>\n",
       "      <td>520966</td>\n",
       "      <td>532569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bexley</th>\n",
       "      <td>E09000004</td>\n",
       "      <td>64958.1</td>\n",
       "      <td>64787.9</td>\n",
       "      <td>64367.5</td>\n",
       "      <td>64277.7</td>\n",
       "      <td>63997.1</td>\n",
       "      <td>64252.3</td>\n",
       "      <td>63722.7</td>\n",
       "      <td>64432.6</td>\n",
       "      <td>64509.5</td>\n",
       "      <td>...</td>\n",
       "      <td>339324</td>\n",
       "      <td>338346</td>\n",
       "      <td>337523</td>\n",
       "      <td>333340</td>\n",
       "      <td>332920</td>\n",
       "      <td>333657</td>\n",
       "      <td>336302</td>\n",
       "      <td>334430</td>\n",
       "      <td>334845</td>\n",
       "      <td>331679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 304 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0                    1                    2    \\\n",
       "Unnamed: 0                NaT  1995-01-01 00:00:00  1995-02-01 00:00:00   \n",
       "City of London      E09000001                91449              82202.8   \n",
       "Barking & Dagenham  E09000002              50460.2              51085.8   \n",
       "Barnet              E09000003              93284.5              93190.2   \n",
       "Bexley              E09000004              64958.1              64787.9   \n",
       "\n",
       "                                    3                    4    \\\n",
       "Unnamed: 0          1995-03-01 00:00:00  1995-04-01 00:00:00   \n",
       "City of London                  79120.7              77101.2   \n",
       "Barking & Dagenham                51269              53133.5   \n",
       "Barnet                          92247.5              90762.9   \n",
       "Bexley                          64367.5              64277.7   \n",
       "\n",
       "                                    5                    6    \\\n",
       "Unnamed: 0          1995-05-01 00:00:00  1995-06-01 00:00:00   \n",
       "City of London                  84409.1              94900.5   \n",
       "Barking & Dagenham              53042.2              53700.3   \n",
       "Barnet                            90258              90107.2   \n",
       "Bexley                          63997.1              64252.3   \n",
       "\n",
       "                                    7                    8    \\\n",
       "Unnamed: 0          1995-07-01 00:00:00  1995-08-01 00:00:00   \n",
       "City of London                   110128               112329   \n",
       "Barking & Dagenham              52113.1              52232.2   \n",
       "Barnet                          91441.2              92361.3   \n",
       "Bexley                          63722.7              64432.6   \n",
       "\n",
       "                                    9    ...                  294  \\\n",
       "Unnamed: 0          1995-09-01 00:00:00  ...  2019-06-01 00:00:00   \n",
       "City of London                   104473  ...               761526   \n",
       "Barking & Dagenham              51471.6  ...               293889   \n",
       "Barnet                          93273.1  ...               512694   \n",
       "Bexley                          64509.5  ...               339324   \n",
       "\n",
       "                                    295                  296  \\\n",
       "Unnamed: 0          2019-07-01 00:00:00  2019-08-01 00:00:00   \n",
       "City of London                   756407               813770   \n",
       "Barking & Dagenham               297426               299421   \n",
       "Barnet                           514668               528577   \n",
       "Bexley                           338346               337523   \n",
       "\n",
       "                                    297                  298  \\\n",
       "Unnamed: 0          2019-09-01 00:00:00  2019-10-01 00:00:00   \n",
       "City of London                   810455               826227   \n",
       "Barking & Dagenham               304778               304579   \n",
       "Barnet                           526670               525678   \n",
       "Bexley                           333340               332920   \n",
       "\n",
       "                                    299                  300  \\\n",
       "Unnamed: 0          2019-11-01 00:00:00  2019-12-01 00:00:00   \n",
       "City of London                   776894               737275   \n",
       "Barking & Dagenham               306390               301283   \n",
       "Barnet                           522639               519306   \n",
       "Bexley                           333657               336302   \n",
       "\n",
       "                                    301                  302  \\\n",
       "Unnamed: 0          2020-01-01 00:00:00  2020-02-01 00:00:00   \n",
       "City of London                   757377               765416   \n",
       "Barking & Dagenham               304187               304719   \n",
       "Barnet                           520115               520966   \n",
       "Bexley                           334430               334845   \n",
       "\n",
       "                                    303  \n",
       "Unnamed: 0          2020-03-01 00:00:00  \n",
       "City of London                   792583  \n",
       "Barking & Dagenham               327136  \n",
       "Barnet                           532569  \n",
       "Bexley                           331679  \n",
       "\n",
       "[5 rows x 304 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the head of our new Transposed DataFrame. \n",
    "properties_T.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fHvxke9XcAVI"
   },
   "source": [
    "You've made some progress! But with new progress comes new issues. For one, the row indices of your DataFrame contain the names of the boroughs. You should never have a piece of information you want to analyze as an index, this information should be within the DataFrame itself. The indices should just be a unique ID, almost always a number.\n",
    "\n",
    "Those names are perhaps the most important piece of information! Put them where you can work with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HdouAxnTcAVJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'City of London', 'Barking & Dagenham', 'Barnet',\n",
       "       'Bexley', 'Brent', 'Bromley', 'Camden', 'Croydon', 'Ealing', 'Enfield',\n",
       "       'Greenwich', 'Hackney', 'Hammersmith & Fulham', 'Haringey', 'Harrow',\n",
       "       'Havering', 'Hillingdon', 'Hounslow', 'Islington',\n",
       "       'Kensington & Chelsea', 'Kingston upon Thames', 'Lambeth', 'Lewisham',\n",
       "       'Merton', 'Newham', 'Redbridge', 'Richmond upon Thames', 'Southwark',\n",
       "       'Sutton', 'Tower Hamlets', 'Waltham Forest', 'Wandsworth',\n",
       "       'Westminster', 'Unnamed: 34', 'Inner London', 'Outer London',\n",
       "       'Unnamed: 37', 'NORTH EAST', 'NORTH WEST', 'YORKS & THE HUMBER',\n",
       "       'EAST MIDLANDS', 'WEST MIDLANDS', 'EAST OF ENGLAND', 'LONDON',\n",
       "       'SOUTH EAST', 'SOUTH WEST', 'Unnamed: 47', 'England'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To confirm what our row indices are, let's call the .index variable on our properties_T DataFrame. \n",
    "properties_T.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aao6yKGFcAVL"
   },
   "outputs": [],
   "source": [
    "# Our suspicion was correct. \n",
    "# Call the .reset_index() method on properties_T to reset the indices, and the reassign the result to properties_T: \n",
    "properties_T = properties_T.reset_index() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tGj6YX1VcAVN"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=49, step=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's check out our DataFrames indices: \n",
    "properties_T.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UZO2SqYTcAVP"
   },
   "source": [
    "\n",
    "Progress! \n",
    "\n",
    "The indicies are now a numerical RangeIndex, exactly what you want. \n",
    "\n",
    "**Note**: if you call the reset_index() line more than once, you'll get an error because a whole extra level of row indices will have been inserted! If you do this, don't worry. Just hit Kernel > Restart, then run all the cells up to here to get back to where you were. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-q99HGLscAVP"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>300</th>\n",
       "      <th>301</th>\n",
       "      <th>302</th>\n",
       "      <th>303</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unnamed: 0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1995-01-01 00:00:00</td>\n",
       "      <td>1995-02-01 00:00:00</td>\n",
       "      <td>1995-03-01 00:00:00</td>\n",
       "      <td>1995-04-01 00:00:00</td>\n",
       "      <td>1995-05-01 00:00:00</td>\n",
       "      <td>1995-06-01 00:00:00</td>\n",
       "      <td>1995-07-01 00:00:00</td>\n",
       "      <td>1995-08-01 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-06-01 00:00:00</td>\n",
       "      <td>2019-07-01 00:00:00</td>\n",
       "      <td>2019-08-01 00:00:00</td>\n",
       "      <td>2019-09-01 00:00:00</td>\n",
       "      <td>2019-10-01 00:00:00</td>\n",
       "      <td>2019-11-01 00:00:00</td>\n",
       "      <td>2019-12-01 00:00:00</td>\n",
       "      <td>2020-01-01 00:00:00</td>\n",
       "      <td>2020-02-01 00:00:00</td>\n",
       "      <td>2020-03-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>City of London</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>91449</td>\n",
       "      <td>82202.8</td>\n",
       "      <td>79120.7</td>\n",
       "      <td>77101.2</td>\n",
       "      <td>84409.1</td>\n",
       "      <td>94900.5</td>\n",
       "      <td>110128</td>\n",
       "      <td>112329</td>\n",
       "      <td>...</td>\n",
       "      <td>761526</td>\n",
       "      <td>756407</td>\n",
       "      <td>813770</td>\n",
       "      <td>810455</td>\n",
       "      <td>826227</td>\n",
       "      <td>776894</td>\n",
       "      <td>737275</td>\n",
       "      <td>757377</td>\n",
       "      <td>765416</td>\n",
       "      <td>792583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barking &amp; Dagenham</td>\n",
       "      <td>E09000002</td>\n",
       "      <td>50460.2</td>\n",
       "      <td>51085.8</td>\n",
       "      <td>51269</td>\n",
       "      <td>53133.5</td>\n",
       "      <td>53042.2</td>\n",
       "      <td>53700.3</td>\n",
       "      <td>52113.1</td>\n",
       "      <td>52232.2</td>\n",
       "      <td>...</td>\n",
       "      <td>293889</td>\n",
       "      <td>297426</td>\n",
       "      <td>299421</td>\n",
       "      <td>304778</td>\n",
       "      <td>304579</td>\n",
       "      <td>306390</td>\n",
       "      <td>301283</td>\n",
       "      <td>304187</td>\n",
       "      <td>304719</td>\n",
       "      <td>327136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Barnet</td>\n",
       "      <td>E09000003</td>\n",
       "      <td>93284.5</td>\n",
       "      <td>93190.2</td>\n",
       "      <td>92247.5</td>\n",
       "      <td>90762.9</td>\n",
       "      <td>90258</td>\n",
       "      <td>90107.2</td>\n",
       "      <td>91441.2</td>\n",
       "      <td>92361.3</td>\n",
       "      <td>...</td>\n",
       "      <td>512694</td>\n",
       "      <td>514668</td>\n",
       "      <td>528577</td>\n",
       "      <td>526670</td>\n",
       "      <td>525678</td>\n",
       "      <td>522639</td>\n",
       "      <td>519306</td>\n",
       "      <td>520115</td>\n",
       "      <td>520966</td>\n",
       "      <td>532569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bexley</td>\n",
       "      <td>E09000004</td>\n",
       "      <td>64958.1</td>\n",
       "      <td>64787.9</td>\n",
       "      <td>64367.5</td>\n",
       "      <td>64277.7</td>\n",
       "      <td>63997.1</td>\n",
       "      <td>64252.3</td>\n",
       "      <td>63722.7</td>\n",
       "      <td>64432.6</td>\n",
       "      <td>...</td>\n",
       "      <td>339324</td>\n",
       "      <td>338346</td>\n",
       "      <td>337523</td>\n",
       "      <td>333340</td>\n",
       "      <td>332920</td>\n",
       "      <td>333657</td>\n",
       "      <td>336302</td>\n",
       "      <td>334430</td>\n",
       "      <td>334845</td>\n",
       "      <td>331679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 305 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                index          0                    1                    2  \\\n",
       "0          Unnamed: 0        NaT  1995-01-01 00:00:00  1995-02-01 00:00:00   \n",
       "1      City of London  E09000001                91449              82202.8   \n",
       "2  Barking & Dagenham  E09000002              50460.2              51085.8   \n",
       "3              Barnet  E09000003              93284.5              93190.2   \n",
       "4              Bexley  E09000004              64958.1              64787.9   \n",
       "\n",
       "                     3                    4                    5  \\\n",
       "0  1995-03-01 00:00:00  1995-04-01 00:00:00  1995-05-01 00:00:00   \n",
       "1              79120.7              77101.2              84409.1   \n",
       "2                51269              53133.5              53042.2   \n",
       "3              92247.5              90762.9                90258   \n",
       "4              64367.5              64277.7              63997.1   \n",
       "\n",
       "                     6                    7                    8  ...  \\\n",
       "0  1995-06-01 00:00:00  1995-07-01 00:00:00  1995-08-01 00:00:00  ...   \n",
       "1              94900.5               110128               112329  ...   \n",
       "2              53700.3              52113.1              52232.2  ...   \n",
       "3              90107.2              91441.2              92361.3  ...   \n",
       "4              64252.3              63722.7              64432.6  ...   \n",
       "\n",
       "                   294                  295                  296  \\\n",
       "0  2019-06-01 00:00:00  2019-07-01 00:00:00  2019-08-01 00:00:00   \n",
       "1               761526               756407               813770   \n",
       "2               293889               297426               299421   \n",
       "3               512694               514668               528577   \n",
       "4               339324               338346               337523   \n",
       "\n",
       "                   297                  298                  299  \\\n",
       "0  2019-09-01 00:00:00  2019-10-01 00:00:00  2019-11-01 00:00:00   \n",
       "1               810455               826227               776894   \n",
       "2               304778               304579               306390   \n",
       "3               526670               525678               522639   \n",
       "4               333340               332920               333657   \n",
       "\n",
       "                   300                  301                  302  \\\n",
       "0  2019-12-01 00:00:00  2020-01-01 00:00:00  2020-02-01 00:00:00   \n",
       "1               737275               757377               765416   \n",
       "2               301283               304187               304719   \n",
       "3               519306               520115               520966   \n",
       "4               336302               334430               334845   \n",
       "\n",
       "                   303  \n",
       "0  2020-03-01 00:00:00  \n",
       "1               792583  \n",
       "2               327136  \n",
       "3               532569  \n",
       "4               331679  \n",
       "\n",
       "[5 rows x 305 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the head() function again on properties_T to check out the new row indices: \n",
    "properties_T.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BaW90dtbcAVR"
   },
   "source": [
    "You're getting somewhere, but our column headings are mainly just integers. The first one is the string 'index' and the rest are integers ranging from 0 to 296, inclusive.\n",
    "\n",
    "\n",
    "For the ultimate aim of having a *tidy* DataFrame, turn the datetimes found along the first row (at index 0) into the column headings.  The resulting DataFrame will have boroughs as rows, the columns as dates (each representing a particular month), and the cell-values as the average property value sold in that borough for that month. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hvdvy-8rcAVR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index',       0,       1,       2,       3,       4,       5,       6,\n",
       "             7,       8,\n",
       "       ...\n",
       "           294,     295,     296,     297,     298,     299,     300,     301,\n",
       "           302,     303],\n",
       "      dtype='object', length=305)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To confirm that our DataFrame's columns are mainly just integers, call the .columns feature on our DataFrame:\n",
    "properties_T.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C_-aS8tncAVT"
   },
   "source": [
    "To confirm that the first row contains the proper values for column headings, use the  ***iloc[] method*** on our *properties_T* DataFrame. Use index 0. You'll recall from DataCamp that if you use single square brackets, you'll return a series. If you use double square brackets, a DataFrame is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6xWcjc1qcAVU"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>300</th>\n",
       "      <th>301</th>\n",
       "      <th>302</th>\n",
       "      <th>303</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unnamed: 0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1995-01-01 00:00:00</td>\n",
       "      <td>1995-02-01 00:00:00</td>\n",
       "      <td>1995-03-01 00:00:00</td>\n",
       "      <td>1995-04-01 00:00:00</td>\n",
       "      <td>1995-05-01 00:00:00</td>\n",
       "      <td>1995-06-01 00:00:00</td>\n",
       "      <td>1995-07-01 00:00:00</td>\n",
       "      <td>1995-08-01 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-06-01 00:00:00</td>\n",
       "      <td>2019-07-01 00:00:00</td>\n",
       "      <td>2019-08-01 00:00:00</td>\n",
       "      <td>2019-09-01 00:00:00</td>\n",
       "      <td>2019-10-01 00:00:00</td>\n",
       "      <td>2019-11-01 00:00:00</td>\n",
       "      <td>2019-12-01 00:00:00</td>\n",
       "      <td>2020-01-01 00:00:00</td>\n",
       "      <td>2020-02-01 00:00:00</td>\n",
       "      <td>2020-03-01 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 305 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index    0                    1                    2  \\\n",
       "0  Unnamed: 0  NaT  1995-01-01 00:00:00  1995-02-01 00:00:00   \n",
       "\n",
       "                     3                    4                    5  \\\n",
       "0  1995-03-01 00:00:00  1995-04-01 00:00:00  1995-05-01 00:00:00   \n",
       "\n",
       "                     6                    7                    8  ...  \\\n",
       "0  1995-06-01 00:00:00  1995-07-01 00:00:00  1995-08-01 00:00:00  ...   \n",
       "\n",
       "                   294                  295                  296  \\\n",
       "0  2019-06-01 00:00:00  2019-07-01 00:00:00  2019-08-01 00:00:00   \n",
       "\n",
       "                   297                  298                  299  \\\n",
       "0  2019-09-01 00:00:00  2019-10-01 00:00:00  2019-11-01 00:00:00   \n",
       "\n",
       "                   300                  301                  302  \\\n",
       "0  2019-12-01 00:00:00  2020-01-01 00:00:00  2020-02-01 00:00:00   \n",
       "\n",
       "                   303  \n",
       "0  2020-03-01 00:00:00  \n",
       "\n",
       "[1 rows x 305 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the iloc[] method with double square brackets on the properties_T DataFrame, to see the row at index 0. \n",
    "properties_T.iloc[[0]] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "szi9ZHrHcAVW"
   },
   "source": [
    "**Notice that these values are all the months from January 1995 to August 2019, inclusive**. You can reassign the columns of your DataFrame the values in the row at index 0 by making use of the *.columns* feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ioW2FRhKcAVW"
   },
   "outputs": [],
   "source": [
    "# Try this now. \n",
    "properties_T.columns = properties_T.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OBHmvVH_cAVa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>NaN</th>\n",
       "      <th>1995-01-01 00:00:00</th>\n",
       "      <th>1995-02-01 00:00:00</th>\n",
       "      <th>1995-03-01 00:00:00</th>\n",
       "      <th>1995-04-01 00:00:00</th>\n",
       "      <th>1995-05-01 00:00:00</th>\n",
       "      <th>1995-06-01 00:00:00</th>\n",
       "      <th>1995-07-01 00:00:00</th>\n",
       "      <th>1995-08-01 00:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2019-06-01 00:00:00</th>\n",
       "      <th>2019-07-01 00:00:00</th>\n",
       "      <th>2019-08-01 00:00:00</th>\n",
       "      <th>2019-09-01 00:00:00</th>\n",
       "      <th>2019-10-01 00:00:00</th>\n",
       "      <th>2019-11-01 00:00:00</th>\n",
       "      <th>2019-12-01 00:00:00</th>\n",
       "      <th>2020-01-01 00:00:00</th>\n",
       "      <th>2020-02-01 00:00:00</th>\n",
       "      <th>2020-03-01 00:00:00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unnamed: 0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1995-01-01 00:00:00</td>\n",
       "      <td>1995-02-01 00:00:00</td>\n",
       "      <td>1995-03-01 00:00:00</td>\n",
       "      <td>1995-04-01 00:00:00</td>\n",
       "      <td>1995-05-01 00:00:00</td>\n",
       "      <td>1995-06-01 00:00:00</td>\n",
       "      <td>1995-07-01 00:00:00</td>\n",
       "      <td>1995-08-01 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-06-01 00:00:00</td>\n",
       "      <td>2019-07-01 00:00:00</td>\n",
       "      <td>2019-08-01 00:00:00</td>\n",
       "      <td>2019-09-01 00:00:00</td>\n",
       "      <td>2019-10-01 00:00:00</td>\n",
       "      <td>2019-11-01 00:00:00</td>\n",
       "      <td>2019-12-01 00:00:00</td>\n",
       "      <td>2020-01-01 00:00:00</td>\n",
       "      <td>2020-02-01 00:00:00</td>\n",
       "      <td>2020-03-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>City of London</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>91449</td>\n",
       "      <td>82202.8</td>\n",
       "      <td>79120.7</td>\n",
       "      <td>77101.2</td>\n",
       "      <td>84409.1</td>\n",
       "      <td>94900.5</td>\n",
       "      <td>110128</td>\n",
       "      <td>112329</td>\n",
       "      <td>...</td>\n",
       "      <td>761526</td>\n",
       "      <td>756407</td>\n",
       "      <td>813770</td>\n",
       "      <td>810455</td>\n",
       "      <td>826227</td>\n",
       "      <td>776894</td>\n",
       "      <td>737275</td>\n",
       "      <td>757377</td>\n",
       "      <td>765416</td>\n",
       "      <td>792583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barking &amp; Dagenham</td>\n",
       "      <td>E09000002</td>\n",
       "      <td>50460.2</td>\n",
       "      <td>51085.8</td>\n",
       "      <td>51269</td>\n",
       "      <td>53133.5</td>\n",
       "      <td>53042.2</td>\n",
       "      <td>53700.3</td>\n",
       "      <td>52113.1</td>\n",
       "      <td>52232.2</td>\n",
       "      <td>...</td>\n",
       "      <td>293889</td>\n",
       "      <td>297426</td>\n",
       "      <td>299421</td>\n",
       "      <td>304778</td>\n",
       "      <td>304579</td>\n",
       "      <td>306390</td>\n",
       "      <td>301283</td>\n",
       "      <td>304187</td>\n",
       "      <td>304719</td>\n",
       "      <td>327136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Barnet</td>\n",
       "      <td>E09000003</td>\n",
       "      <td>93284.5</td>\n",
       "      <td>93190.2</td>\n",
       "      <td>92247.5</td>\n",
       "      <td>90762.9</td>\n",
       "      <td>90258</td>\n",
       "      <td>90107.2</td>\n",
       "      <td>91441.2</td>\n",
       "      <td>92361.3</td>\n",
       "      <td>...</td>\n",
       "      <td>512694</td>\n",
       "      <td>514668</td>\n",
       "      <td>528577</td>\n",
       "      <td>526670</td>\n",
       "      <td>525678</td>\n",
       "      <td>522639</td>\n",
       "      <td>519306</td>\n",
       "      <td>520115</td>\n",
       "      <td>520966</td>\n",
       "      <td>532569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bexley</td>\n",
       "      <td>E09000004</td>\n",
       "      <td>64958.1</td>\n",
       "      <td>64787.9</td>\n",
       "      <td>64367.5</td>\n",
       "      <td>64277.7</td>\n",
       "      <td>63997.1</td>\n",
       "      <td>64252.3</td>\n",
       "      <td>63722.7</td>\n",
       "      <td>64432.6</td>\n",
       "      <td>...</td>\n",
       "      <td>339324</td>\n",
       "      <td>338346</td>\n",
       "      <td>337523</td>\n",
       "      <td>333340</td>\n",
       "      <td>332920</td>\n",
       "      <td>333657</td>\n",
       "      <td>336302</td>\n",
       "      <td>334430</td>\n",
       "      <td>334845</td>\n",
       "      <td>331679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 305 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0          Unnamed: 0        NaN  1995-01-01 00:00:00  1995-02-01 00:00:00  \\\n",
       "0          Unnamed: 0        NaT  1995-01-01 00:00:00  1995-02-01 00:00:00   \n",
       "1      City of London  E09000001                91449              82202.8   \n",
       "2  Barking & Dagenham  E09000002              50460.2              51085.8   \n",
       "3              Barnet  E09000003              93284.5              93190.2   \n",
       "4              Bexley  E09000004              64958.1              64787.9   \n",
       "\n",
       "0  1995-03-01 00:00:00  1995-04-01 00:00:00  1995-05-01 00:00:00  \\\n",
       "0  1995-03-01 00:00:00  1995-04-01 00:00:00  1995-05-01 00:00:00   \n",
       "1              79120.7              77101.2              84409.1   \n",
       "2                51269              53133.5              53042.2   \n",
       "3              92247.5              90762.9                90258   \n",
       "4              64367.5              64277.7              63997.1   \n",
       "\n",
       "0  1995-06-01 00:00:00  1995-07-01 00:00:00  1995-08-01 00:00:00  ...  \\\n",
       "0  1995-06-01 00:00:00  1995-07-01 00:00:00  1995-08-01 00:00:00  ...   \n",
       "1              94900.5               110128               112329  ...   \n",
       "2              53700.3              52113.1              52232.2  ...   \n",
       "3              90107.2              91441.2              92361.3  ...   \n",
       "4              64252.3              63722.7              64432.6  ...   \n",
       "\n",
       "0  2019-06-01 00:00:00  2019-07-01 00:00:00  2019-08-01 00:00:00  \\\n",
       "0  2019-06-01 00:00:00  2019-07-01 00:00:00  2019-08-01 00:00:00   \n",
       "1               761526               756407               813770   \n",
       "2               293889               297426               299421   \n",
       "3               512694               514668               528577   \n",
       "4               339324               338346               337523   \n",
       "\n",
       "0  2019-09-01 00:00:00  2019-10-01 00:00:00  2019-11-01 00:00:00  \\\n",
       "0  2019-09-01 00:00:00  2019-10-01 00:00:00  2019-11-01 00:00:00   \n",
       "1               810455               826227               776894   \n",
       "2               304778               304579               306390   \n",
       "3               526670               525678               522639   \n",
       "4               333340               332920               333657   \n",
       "\n",
       "0  2019-12-01 00:00:00  2020-01-01 00:00:00  2020-02-01 00:00:00  \\\n",
       "0  2019-12-01 00:00:00  2020-01-01 00:00:00  2020-02-01 00:00:00   \n",
       "1               737275               757377               765416   \n",
       "2               301283               304187               304719   \n",
       "3               519306               520115               520966   \n",
       "4               336302               334430               334845   \n",
       "\n",
       "0  2020-03-01 00:00:00  \n",
       "0  2020-03-01 00:00:00  \n",
       "1               792583  \n",
       "2               327136  \n",
       "3               532569  \n",
       "4               331679  \n",
       "\n",
       "[5 rows x 305 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out our DataFrame again: \n",
    "properties_T.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l9Pa-QvrcAVb"
   },
   "source": [
    "Drop the row at index 0! \n",
    "\n",
    "A good way to do this is reassign *properties_T* the value given by the result of calling ***drop()*** on it, with 0 passed to that method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TiWzfXKfcAVc"
   },
   "outputs": [],
   "source": [
    "# Have a go at this now. \n",
    "properties_T = properties_T.drop(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B32bbCFQcAVd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>NaN</th>\n",
       "      <th>1995-01-01 00:00:00</th>\n",
       "      <th>1995-02-01 00:00:00</th>\n",
       "      <th>1995-03-01 00:00:00</th>\n",
       "      <th>1995-04-01 00:00:00</th>\n",
       "      <th>1995-05-01 00:00:00</th>\n",
       "      <th>1995-06-01 00:00:00</th>\n",
       "      <th>1995-07-01 00:00:00</th>\n",
       "      <th>1995-08-01 00:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2019-06-01 00:00:00</th>\n",
       "      <th>2019-07-01 00:00:00</th>\n",
       "      <th>2019-08-01 00:00:00</th>\n",
       "      <th>2019-09-01 00:00:00</th>\n",
       "      <th>2019-10-01 00:00:00</th>\n",
       "      <th>2019-11-01 00:00:00</th>\n",
       "      <th>2019-12-01 00:00:00</th>\n",
       "      <th>2020-01-01 00:00:00</th>\n",
       "      <th>2020-02-01 00:00:00</th>\n",
       "      <th>2020-03-01 00:00:00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>City of London</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>91449</td>\n",
       "      <td>82202.8</td>\n",
       "      <td>79120.7</td>\n",
       "      <td>77101.2</td>\n",
       "      <td>84409.1</td>\n",
       "      <td>94900.5</td>\n",
       "      <td>110128</td>\n",
       "      <td>112329</td>\n",
       "      <td>...</td>\n",
       "      <td>761526</td>\n",
       "      <td>756407</td>\n",
       "      <td>813770</td>\n",
       "      <td>810455</td>\n",
       "      <td>826227</td>\n",
       "      <td>776894</td>\n",
       "      <td>737275</td>\n",
       "      <td>757377</td>\n",
       "      <td>765416</td>\n",
       "      <td>792583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barking &amp; Dagenham</td>\n",
       "      <td>E09000002</td>\n",
       "      <td>50460.2</td>\n",
       "      <td>51085.8</td>\n",
       "      <td>51269</td>\n",
       "      <td>53133.5</td>\n",
       "      <td>53042.2</td>\n",
       "      <td>53700.3</td>\n",
       "      <td>52113.1</td>\n",
       "      <td>52232.2</td>\n",
       "      <td>...</td>\n",
       "      <td>293889</td>\n",
       "      <td>297426</td>\n",
       "      <td>299421</td>\n",
       "      <td>304778</td>\n",
       "      <td>304579</td>\n",
       "      <td>306390</td>\n",
       "      <td>301283</td>\n",
       "      <td>304187</td>\n",
       "      <td>304719</td>\n",
       "      <td>327136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Barnet</td>\n",
       "      <td>E09000003</td>\n",
       "      <td>93284.5</td>\n",
       "      <td>93190.2</td>\n",
       "      <td>92247.5</td>\n",
       "      <td>90762.9</td>\n",
       "      <td>90258</td>\n",
       "      <td>90107.2</td>\n",
       "      <td>91441.2</td>\n",
       "      <td>92361.3</td>\n",
       "      <td>...</td>\n",
       "      <td>512694</td>\n",
       "      <td>514668</td>\n",
       "      <td>528577</td>\n",
       "      <td>526670</td>\n",
       "      <td>525678</td>\n",
       "      <td>522639</td>\n",
       "      <td>519306</td>\n",
       "      <td>520115</td>\n",
       "      <td>520966</td>\n",
       "      <td>532569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bexley</td>\n",
       "      <td>E09000004</td>\n",
       "      <td>64958.1</td>\n",
       "      <td>64787.9</td>\n",
       "      <td>64367.5</td>\n",
       "      <td>64277.7</td>\n",
       "      <td>63997.1</td>\n",
       "      <td>64252.3</td>\n",
       "      <td>63722.7</td>\n",
       "      <td>64432.6</td>\n",
       "      <td>...</td>\n",
       "      <td>339324</td>\n",
       "      <td>338346</td>\n",
       "      <td>337523</td>\n",
       "      <td>333340</td>\n",
       "      <td>332920</td>\n",
       "      <td>333657</td>\n",
       "      <td>336302</td>\n",
       "      <td>334430</td>\n",
       "      <td>334845</td>\n",
       "      <td>331679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Brent</td>\n",
       "      <td>E09000005</td>\n",
       "      <td>71306.6</td>\n",
       "      <td>72022.3</td>\n",
       "      <td>72015.8</td>\n",
       "      <td>72965.6</td>\n",
       "      <td>73704</td>\n",
       "      <td>74310.5</td>\n",
       "      <td>74127</td>\n",
       "      <td>73547</td>\n",
       "      <td>...</td>\n",
       "      <td>474821</td>\n",
       "      <td>473849</td>\n",
       "      <td>488784</td>\n",
       "      <td>501533</td>\n",
       "      <td>494770</td>\n",
       "      <td>432188</td>\n",
       "      <td>427126</td>\n",
       "      <td>424663</td>\n",
       "      <td>471574</td>\n",
       "      <td>446966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 305 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0          Unnamed: 0        NaN 1995-01-01 00:00:00 1995-02-01 00:00:00  \\\n",
       "1      City of London  E09000001               91449             82202.8   \n",
       "2  Barking & Dagenham  E09000002             50460.2             51085.8   \n",
       "3              Barnet  E09000003             93284.5             93190.2   \n",
       "4              Bexley  E09000004             64958.1             64787.9   \n",
       "5               Brent  E09000005             71306.6             72022.3   \n",
       "\n",
       "0 1995-03-01 00:00:00 1995-04-01 00:00:00 1995-05-01 00:00:00  \\\n",
       "1             79120.7             77101.2             84409.1   \n",
       "2               51269             53133.5             53042.2   \n",
       "3             92247.5             90762.9               90258   \n",
       "4             64367.5             64277.7             63997.1   \n",
       "5             72015.8             72965.6               73704   \n",
       "\n",
       "0 1995-06-01 00:00:00 1995-07-01 00:00:00 1995-08-01 00:00:00  ...  \\\n",
       "1             94900.5              110128              112329  ...   \n",
       "2             53700.3             52113.1             52232.2  ...   \n",
       "3             90107.2             91441.2             92361.3  ...   \n",
       "4             64252.3             63722.7             64432.6  ...   \n",
       "5             74310.5               74127               73547  ...   \n",
       "\n",
       "0 2019-06-01 00:00:00 2019-07-01 00:00:00 2019-08-01 00:00:00  \\\n",
       "1              761526              756407              813770   \n",
       "2              293889              297426              299421   \n",
       "3              512694              514668              528577   \n",
       "4              339324              338346              337523   \n",
       "5              474821              473849              488784   \n",
       "\n",
       "0 2019-09-01 00:00:00 2019-10-01 00:00:00 2019-11-01 00:00:00  \\\n",
       "1              810455              826227              776894   \n",
       "2              304778              304579              306390   \n",
       "3              526670              525678              522639   \n",
       "4              333340              332920              333657   \n",
       "5              501533              494770              432188   \n",
       "\n",
       "0 2019-12-01 00:00:00 2020-01-01 00:00:00 2020-02-01 00:00:00  \\\n",
       "1              737275              757377              765416   \n",
       "2              301283              304187              304719   \n",
       "3              519306              520115              520966   \n",
       "4              336302              334430              334845   \n",
       "5              427126              424663              471574   \n",
       "\n",
       "0 2020-03-01 00:00:00  \n",
       "1              792583  \n",
       "2              327136  \n",
       "3              532569  \n",
       "4              331679  \n",
       "5              446966  \n",
       "\n",
       "[5 rows x 305 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now check out our DataFrame again to see how it looks. \n",
    "properties_T.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R1Teru9ecAVh"
   },
   "source": [
    "You're slowly but surely getting there! Exciting, right? \n",
    "\n",
    "**Each column now represents a month and year, and each cell-value represents the average price of houses sold in borough of the corresponding row**. \n",
    "\n",
    "You have total control over your data! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UazH1Wh_cAVi"
   },
   "source": [
    "#### 2.3. Cleaning the data (Part 2)\n",
    "You can see from the *.head()* list call that you need to rename some of your columns. \n",
    "\n",
    "'Unnamed: 0' should be something like 'London Borough' and 'NaN' should  be changed. \n",
    "\n",
    "Recall, that pandas DataFrames have a ***.rename()*** method. One of the keyworded arguments to this method is *columns*. You can assign it a dictionary whose keys are the current column names you want to change, and whose values are the desired new names.\n",
    "\n",
    "**Note**: you can change the 'Unnamed: 0' name of the first column just by including that string as a key in our dictionary, but 'NaN' stands for Not A Number,  and is denoted by *pd.NaT*. Do not use quotes when you include this value. NaN means Not A Number, and NaT means Not A Time - both of these values represent undefined or unrepresenable values like 0/0. They are functionally Null values. Don't worry, we'll help you with this.\n",
    "\n",
    " Call the **rename()** method on *properties_T* and set the *columns* keyword equal to the following dictionary: \n",
    "{'Unnamed: 0':'London_Borough', pd.NaT: 'ID'} \n",
    ", then reassign that value to properties_T to update the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M5kHlbxucAVi"
   },
   "outputs": [],
   "source": [
    "# Try this here. \n",
    "properties_T = properties_T.rename(columns = {'Unnamed: 0':'London_Borough', pd.NaT: 'ID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CI5yUUK6cAVl"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>London_Borough</th>\n",
       "      <th>ID</th>\n",
       "      <th>1995-01-01 00:00:00</th>\n",
       "      <th>1995-02-01 00:00:00</th>\n",
       "      <th>1995-03-01 00:00:00</th>\n",
       "      <th>1995-04-01 00:00:00</th>\n",
       "      <th>1995-05-01 00:00:00</th>\n",
       "      <th>1995-06-01 00:00:00</th>\n",
       "      <th>1995-07-01 00:00:00</th>\n",
       "      <th>1995-08-01 00:00:00</th>\n",
       "      <th>...</th>\n",
       "      <th>2019-06-01 00:00:00</th>\n",
       "      <th>2019-07-01 00:00:00</th>\n",
       "      <th>2019-08-01 00:00:00</th>\n",
       "      <th>2019-09-01 00:00:00</th>\n",
       "      <th>2019-10-01 00:00:00</th>\n",
       "      <th>2019-11-01 00:00:00</th>\n",
       "      <th>2019-12-01 00:00:00</th>\n",
       "      <th>2020-01-01 00:00:00</th>\n",
       "      <th>2020-02-01 00:00:00</th>\n",
       "      <th>2020-03-01 00:00:00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>City of London</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>91449</td>\n",
       "      <td>82202.8</td>\n",
       "      <td>79120.7</td>\n",
       "      <td>77101.2</td>\n",
       "      <td>84409.1</td>\n",
       "      <td>94900.5</td>\n",
       "      <td>110128</td>\n",
       "      <td>112329</td>\n",
       "      <td>...</td>\n",
       "      <td>761526</td>\n",
       "      <td>756407</td>\n",
       "      <td>813770</td>\n",
       "      <td>810455</td>\n",
       "      <td>826227</td>\n",
       "      <td>776894</td>\n",
       "      <td>737275</td>\n",
       "      <td>757377</td>\n",
       "      <td>765416</td>\n",
       "      <td>792583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barking &amp; Dagenham</td>\n",
       "      <td>E09000002</td>\n",
       "      <td>50460.2</td>\n",
       "      <td>51085.8</td>\n",
       "      <td>51269</td>\n",
       "      <td>53133.5</td>\n",
       "      <td>53042.2</td>\n",
       "      <td>53700.3</td>\n",
       "      <td>52113.1</td>\n",
       "      <td>52232.2</td>\n",
       "      <td>...</td>\n",
       "      <td>293889</td>\n",
       "      <td>297426</td>\n",
       "      <td>299421</td>\n",
       "      <td>304778</td>\n",
       "      <td>304579</td>\n",
       "      <td>306390</td>\n",
       "      <td>301283</td>\n",
       "      <td>304187</td>\n",
       "      <td>304719</td>\n",
       "      <td>327136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Barnet</td>\n",
       "      <td>E09000003</td>\n",
       "      <td>93284.5</td>\n",
       "      <td>93190.2</td>\n",
       "      <td>92247.5</td>\n",
       "      <td>90762.9</td>\n",
       "      <td>90258</td>\n",
       "      <td>90107.2</td>\n",
       "      <td>91441.2</td>\n",
       "      <td>92361.3</td>\n",
       "      <td>...</td>\n",
       "      <td>512694</td>\n",
       "      <td>514668</td>\n",
       "      <td>528577</td>\n",
       "      <td>526670</td>\n",
       "      <td>525678</td>\n",
       "      <td>522639</td>\n",
       "      <td>519306</td>\n",
       "      <td>520115</td>\n",
       "      <td>520966</td>\n",
       "      <td>532569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bexley</td>\n",
       "      <td>E09000004</td>\n",
       "      <td>64958.1</td>\n",
       "      <td>64787.9</td>\n",
       "      <td>64367.5</td>\n",
       "      <td>64277.7</td>\n",
       "      <td>63997.1</td>\n",
       "      <td>64252.3</td>\n",
       "      <td>63722.7</td>\n",
       "      <td>64432.6</td>\n",
       "      <td>...</td>\n",
       "      <td>339324</td>\n",
       "      <td>338346</td>\n",
       "      <td>337523</td>\n",
       "      <td>333340</td>\n",
       "      <td>332920</td>\n",
       "      <td>333657</td>\n",
       "      <td>336302</td>\n",
       "      <td>334430</td>\n",
       "      <td>334845</td>\n",
       "      <td>331679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Brent</td>\n",
       "      <td>E09000005</td>\n",
       "      <td>71306.6</td>\n",
       "      <td>72022.3</td>\n",
       "      <td>72015.8</td>\n",
       "      <td>72965.6</td>\n",
       "      <td>73704</td>\n",
       "      <td>74310.5</td>\n",
       "      <td>74127</td>\n",
       "      <td>73547</td>\n",
       "      <td>...</td>\n",
       "      <td>474821</td>\n",
       "      <td>473849</td>\n",
       "      <td>488784</td>\n",
       "      <td>501533</td>\n",
       "      <td>494770</td>\n",
       "      <td>432188</td>\n",
       "      <td>427126</td>\n",
       "      <td>424663</td>\n",
       "      <td>471574</td>\n",
       "      <td>446966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 305 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0      London_Borough         ID 1995-01-01 00:00:00 1995-02-01 00:00:00  \\\n",
       "1      City of London  E09000001               91449             82202.8   \n",
       "2  Barking & Dagenham  E09000002             50460.2             51085.8   \n",
       "3              Barnet  E09000003             93284.5             93190.2   \n",
       "4              Bexley  E09000004             64958.1             64787.9   \n",
       "5               Brent  E09000005             71306.6             72022.3   \n",
       "\n",
       "0 1995-03-01 00:00:00 1995-04-01 00:00:00 1995-05-01 00:00:00  \\\n",
       "1             79120.7             77101.2             84409.1   \n",
       "2               51269             53133.5             53042.2   \n",
       "3             92247.5             90762.9               90258   \n",
       "4             64367.5             64277.7             63997.1   \n",
       "5             72015.8             72965.6               73704   \n",
       "\n",
       "0 1995-06-01 00:00:00 1995-07-01 00:00:00 1995-08-01 00:00:00  ...  \\\n",
       "1             94900.5              110128              112329  ...   \n",
       "2             53700.3             52113.1             52232.2  ...   \n",
       "3             90107.2             91441.2             92361.3  ...   \n",
       "4             64252.3             63722.7             64432.6  ...   \n",
       "5             74310.5               74127               73547  ...   \n",
       "\n",
       "0 2019-06-01 00:00:00 2019-07-01 00:00:00 2019-08-01 00:00:00  \\\n",
       "1              761526              756407              813770   \n",
       "2              293889              297426              299421   \n",
       "3              512694              514668              528577   \n",
       "4              339324              338346              337523   \n",
       "5              474821              473849              488784   \n",
       "\n",
       "0 2019-09-01 00:00:00 2019-10-01 00:00:00 2019-11-01 00:00:00  \\\n",
       "1              810455              826227              776894   \n",
       "2              304778              304579              306390   \n",
       "3              526670              525678              522639   \n",
       "4              333340              332920              333657   \n",
       "5              501533              494770              432188   \n",
       "\n",
       "0 2019-12-01 00:00:00 2020-01-01 00:00:00 2020-02-01 00:00:00  \\\n",
       "1              737275              757377              765416   \n",
       "2              301283              304187              304719   \n",
       "3              519306              520115              520966   \n",
       "4              336302              334430              334845   \n",
       "5              427126              424663              471574   \n",
       "\n",
       "0 2020-03-01 00:00:00  \n",
       "1              792583  \n",
       "2              327136  \n",
       "3              532569  \n",
       "4              331679  \n",
       "5              446966  \n",
       "\n",
       "[5 rows x 305 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check out the DataFrame again to admire our good work. \n",
    "properties_T.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rd8YFt0CcAVn"
   },
   "source": [
    "You're making great leaps forward, but your DataFrame still has lots of columns. Let's find out exactly how many it has by calling ***.columns*** on our DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZnBbY8iFcAVn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([   'London_Borough',                'ID', 1995-01-01 00:00:00,\n",
       "       1995-02-01 00:00:00, 1995-03-01 00:00:00, 1995-04-01 00:00:00,\n",
       "       1995-05-01 00:00:00, 1995-06-01 00:00:00, 1995-07-01 00:00:00,\n",
       "       1995-08-01 00:00:00,\n",
       "       ...\n",
       "       2019-06-01 00:00:00, 2019-07-01 00:00:00, 2019-08-01 00:00:00,\n",
       "       2019-09-01 00:00:00, 2019-10-01 00:00:00, 2019-11-01 00:00:00,\n",
       "       2019-12-01 00:00:00, 2020-01-01 00:00:00, 2020-02-01 00:00:00,\n",
       "       2020-03-01 00:00:00],\n",
       "      dtype='object', name=0, length=305)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try this here. \n",
    "properties_T.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O1ZskDM0cAVp"
   },
   "source": [
    "#### 2.4. Transforming the data\n",
    "Our data would be tidier if we had fewer columns. \n",
    "\n",
    "In fact a ***single*** column for time be better than nearly 300? This single column will contain all of the datetimes in our current column headings. \n",
    "\n",
    "**Remember** the two most important properties of tidy data are:\n",
    "1. **Each column is a variable.**\n",
    "\n",
    "2. **Each row is an observation.**\n",
    "\n",
    "One of the miraculous things about pandas is ***melt()***, which enables us to melt those values along the column headings of our current DataFrame into a single column.  \n",
    "\n",
    "Let's make a new DataFrame called clean_properties, and assign it the return value of ***pd.melt()*** with the parameters: *properties_T* and *id_vars = ['Borough', 'ID']*. \n",
    "\n",
    "The result will be a DataFrame with rows representing the average house price within a given month and a given borough. Exactly what we want. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eZ4-eIHAcAVp"
   },
   "outputs": [],
   "source": [
    "# Try this here: \n",
    "clean_properties = pd.melt(properties_T, id_vars= ['London_Borough', 'ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ukbTKJ9gcAVr"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>London_Borough</th>\n",
       "      <th>ID</th>\n",
       "      <th>0</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>City of London</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>91449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barking &amp; Dagenham</td>\n",
       "      <td>E09000002</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>50460.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barnet</td>\n",
       "      <td>E09000003</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>93284.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bexley</td>\n",
       "      <td>E09000004</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>64958.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brent</td>\n",
       "      <td>E09000005</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>71306.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       London_Borough         ID          0    value\n",
       "0      City of London  E09000001 1995-01-01    91449\n",
       "1  Barking & Dagenham  E09000002 1995-01-01  50460.2\n",
       "2              Barnet  E09000003 1995-01-01  93284.5\n",
       "3              Bexley  E09000004 1995-01-01  64958.1\n",
       "4               Brent  E09000005 1995-01-01  71306.6"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_properties.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GveQuAwCcAVs"
   },
   "source": [
    "Awesome. This is looking good. \n",
    "\n",
    "We now want to rename the '0' column 'Month', and the 'value' column 'Average_price'. \n",
    "\n",
    "Use the ***rename()*** method, and reassign *clean_properties* with the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cef4yksfcAVt"
   },
   "outputs": [],
   "source": [
    "# Re-name the column names\n",
    "clean_properties = clean_properties.rename(columns = {0: 'Month', 'value': 'Average_price'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9CCkY4mdcAVv"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>London_Borough</th>\n",
       "      <th>ID</th>\n",
       "      <th>Month</th>\n",
       "      <th>Average_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>City of London</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>91449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barking &amp; Dagenham</td>\n",
       "      <td>E09000002</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>50460.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barnet</td>\n",
       "      <td>E09000003</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>93284.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bexley</td>\n",
       "      <td>E09000004</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>64958.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brent</td>\n",
       "      <td>E09000005</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>71306.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       London_Borough         ID      Month Average_price\n",
       "0      City of London  E09000001 1995-01-01         91449\n",
       "1  Barking & Dagenham  E09000002 1995-01-01       50460.2\n",
       "2              Barnet  E09000003 1995-01-01       93284.5\n",
       "3              Bexley  E09000004 1995-01-01       64958.1\n",
       "4               Brent  E09000005 1995-01-01       71306.6"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out the DataFrame: \n",
    "clean_properties.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RSUuXokncAVx"
   },
   "source": [
    "You need to check out the data types of our clean_properties DataFrame, just in case you need to do any type conversions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BW6IB1vzcAVx"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "London_Borough            object\n",
       "ID                        object\n",
       "Month             datetime64[ns]\n",
       "Average_price             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's use the .dtypes attribute to check the data types of our clean_properties DataFrame:\n",
    "clean_properties.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rz9pr-TBcAVz"
   },
   "source": [
    "You should change the Average_price column to a numeric type, specifically, a float.\n",
    "\n",
    "Call the ***to_numeric()*** method on *pd*, pass the 'Average_price' column into its brackets, and reassign the result to the *clean_properties* 'Average_price' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W3UQDMuNcAV0"
   },
   "outputs": [],
   "source": [
    "# Try this here\n",
    "clean_properties['Average_price'] = pd.to_numeric(clean_properties['Average_price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eP80X64kcAV2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "London_Borough            object\n",
       "ID                        object\n",
       "Month             datetime64[ns]\n",
       "Average_price            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out the new data types:\n",
    "clean_properties.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AjYRqVAycAV3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "London_Borough    14544\n",
       "ID                13635\n",
       "Month             14544\n",
       "Average_price     13635\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see if there are any missing values, we should call the count() method on our DataFrame:\n",
    "clean_properties.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NGqAbVlMcAV5"
   },
   "source": [
    "#### 2.5. Cleaning the data (Part 3) \n",
    "Houston, we have a problem!\n",
    "\n",
    "There are fewer data points in some of the columns. Why might this be? Let's investigate.\n",
    "\n",
    "Since there are only 32 London boroughs, check out the unique values of the 'London_Borough' column to see if they're all there.\n",
    "\n",
    "Just call the ***unique()*** method on the London_Borough column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jWsQtcrtcAV6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['City of London', 'Barking & Dagenham', 'Barnet', 'Bexley',\n",
       "       'Brent', 'Bromley', 'Camden', 'Croydon', 'Ealing', 'Enfield',\n",
       "       'Greenwich', 'Hackney', 'Hammersmith & Fulham', 'Haringey',\n",
       "       'Harrow', 'Havering', 'Hillingdon', 'Hounslow', 'Islington',\n",
       "       'Kensington & Chelsea', 'Kingston upon Thames', 'Lambeth',\n",
       "       'Lewisham', 'Merton', 'Newham', 'Redbridge',\n",
       "       'Richmond upon Thames', 'Southwark', 'Sutton', 'Tower Hamlets',\n",
       "       'Waltham Forest', 'Wandsworth', 'Westminster', 'Unnamed: 34',\n",
       "       'Inner London', 'Outer London', 'Unnamed: 37', 'NORTH EAST',\n",
       "       'NORTH WEST', 'YORKS & THE HUMBER', 'EAST MIDLANDS',\n",
       "       'WEST MIDLANDS', 'EAST OF ENGLAND', 'LONDON', 'SOUTH EAST',\n",
       "       'SOUTH WEST', 'Unnamed: 47', 'England'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do this here. \n",
    "clean_properties['London_Borough'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sk9R8sNpcAV7"
   },
   "source": [
    "Aha! Some of these strings are not London boroughs. You're basically Sherlock Holmes, getting ever closer solving the mystery! \n",
    "\n",
    "The strings that don't belong:\n",
    "- 'Unnamed: 34'\n",
    "- 'Unnamed: 37'\n",
    "- 'NORTH EAST'\n",
    "- 'NORTH WEST'\n",
    "- 'YORKS & THE HUMBER' \n",
    "- 'EAST MIDLANDS'\n",
    "- 'WEST MIDLANDS'\n",
    "- 'EAST OF ENGLAND'\n",
    "- 'LONDON' \n",
    "- 'SOUTH EAST' \n",
    "- 'SOUTH WEST'\n",
    "- 'Unnamed: 47' \n",
    "- 'England'\n",
    "\n",
    "Go see what information is contained in rows where London_Boroughs is 'Unnamed’ and, if there’s nothing valuable, we can drop them.  To investigate, subset the clean_properties DataFrame on this condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mk1e3woZcAV8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>London_Borough</th>\n",
       "      <th>ID</th>\n",
       "      <th>Month</th>\n",
       "      <th>Average_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Unnamed: 34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Unnamed: 34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1995-02-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Unnamed: 34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1995-03-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>Unnamed: 34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1995-04-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>Unnamed: 34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1995-05-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    London_Borough   ID      Month  Average_price\n",
       "33     Unnamed: 34  NaN 1995-01-01            NaN\n",
       "81     Unnamed: 34  NaN 1995-02-01            NaN\n",
       "129    Unnamed: 34  NaN 1995-03-01            NaN\n",
       "177    Unnamed: 34  NaN 1995-04-01            NaN\n",
       "225    Unnamed: 34  NaN 1995-05-01            NaN"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subset clean_properties on the condition: df['London_Borough'] == 'Unnamed: 34' to see what information these rows contain. \n",
    "clean_properties[clean_properties['London_Borough'] == 'Unnamed: 34'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P1Uqu0q9cAV9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>London_Borough</th>\n",
       "      <th>ID</th>\n",
       "      <th>Month</th>\n",
       "      <th>Average_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Unnamed: 37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Unnamed: 37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1995-02-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>Unnamed: 37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1995-03-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>Unnamed: 37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1995-04-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>Unnamed: 37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1995-05-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    London_Borough   ID      Month  Average_price\n",
       "36     Unnamed: 37  NaN 1995-01-01            NaN\n",
       "84     Unnamed: 37  NaN 1995-02-01            NaN\n",
       "132    Unnamed: 37  NaN 1995-03-01            NaN\n",
       "180    Unnamed: 37  NaN 1995-04-01            NaN\n",
       "228    Unnamed: 37  NaN 1995-05-01            NaN"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's do the same for 'Unnamed: 37':\n",
    "clean_properties[clean_properties['London_Borough'] == 'Unnamed: 37'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2mRyfAgXcAV_"
   },
   "source": [
    "These rows don't contain any valuable information. Delete them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OlvJPQ6KcAWA"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>London_Borough</th>\n",
       "      <th>ID</th>\n",
       "      <th>Month</th>\n",
       "      <th>Average_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Unnamed: 34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Unnamed: 37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Unnamed: 47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Unnamed: 34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1995-02-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Unnamed: 37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1995-02-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14484</th>\n",
       "      <td>Unnamed: 37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14494</th>\n",
       "      <td>Unnamed: 47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14529</th>\n",
       "      <td>Unnamed: 34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14532</th>\n",
       "      <td>Unnamed: 37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14542</th>\n",
       "      <td>Unnamed: 47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>909 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      London_Borough   ID      Month  Average_price\n",
       "33       Unnamed: 34  NaN 1995-01-01            NaN\n",
       "36       Unnamed: 37  NaN 1995-01-01            NaN\n",
       "46       Unnamed: 47  NaN 1995-01-01            NaN\n",
       "81       Unnamed: 34  NaN 1995-02-01            NaN\n",
       "84       Unnamed: 37  NaN 1995-02-01            NaN\n",
       "...              ...  ...        ...            ...\n",
       "14484    Unnamed: 37  NaN 2020-02-01            NaN\n",
       "14494    Unnamed: 47  NaN 2020-02-01            NaN\n",
       "14529    Unnamed: 34  NaN 2020-03-01            NaN\n",
       "14532    Unnamed: 37  NaN 2020-03-01            NaN\n",
       "14542    Unnamed: 47  NaN 2020-03-01            NaN\n",
       "\n",
       "[909 rows x 4 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at how many rows have NAs as their value for ID. \n",
    "# To this end, subset clean_properties on the condition: clean_properties['ID'].isna().\n",
    "# Notice that this line doesn't actually reassign a new value to clean_properties. \n",
    "clean_properties[clean_properties['ID'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DOPMYa-8cAWD"
   },
   "source": [
    "You always have a ***choice*** about how to deal with Null (NaN) values. We'll teach you two methods today:\n",
    "1. filtering on ***notna()***\n",
    "2. reassigning on ***dropna()***\n",
    "\n",
    "Try ***notna()*** first.  ***notna()*** will return a series of booleans, where the value will be true if there's a not a null and false if there is a null.\n",
    "\n",
    "Make a new variable called *NaNFreeDF1* and assign it the result of filtering *clean_properties* on the condition: *clean_properties['Average_price'].notna()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZY9aC1zHcAWD"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>London_Borough</th>\n",
       "      <th>ID</th>\n",
       "      <th>Month</th>\n",
       "      <th>Average_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>City of London</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>91448.98487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barking &amp; Dagenham</td>\n",
       "      <td>E09000002</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>50460.22660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barnet</td>\n",
       "      <td>E09000003</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>93284.51832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bexley</td>\n",
       "      <td>E09000004</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>64958.09036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brent</td>\n",
       "      <td>E09000005</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>71306.56698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bromley</td>\n",
       "      <td>E09000006</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>81671.47692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Camden</td>\n",
       "      <td>E09000007</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>120932.88810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Croydon</td>\n",
       "      <td>E09000008</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>69158.16225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ealing</td>\n",
       "      <td>E09000009</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>79885.89069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Enfield</td>\n",
       "      <td>E09000010</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>72514.69096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Greenwich</td>\n",
       "      <td>E09000011</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>62300.10169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Hackney</td>\n",
       "      <td>E09000012</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>61296.52637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hammersmith &amp; Fulham</td>\n",
       "      <td>E09000013</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>124902.86020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Haringey</td>\n",
       "      <td>E09000014</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>76287.56947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Harrow</td>\n",
       "      <td>E09000015</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>84769.52599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Havering</td>\n",
       "      <td>E09000016</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>68000.13774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Hillingdon</td>\n",
       "      <td>E09000017</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>73834.82964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Hounslow</td>\n",
       "      <td>E09000018</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>72231.70537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Islington</td>\n",
       "      <td>E09000019</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>92516.48557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Kensington &amp; Chelsea</td>\n",
       "      <td>E09000020</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>182694.83260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Kingston upon Thames</td>\n",
       "      <td>E09000021</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>80875.84843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Lambeth</td>\n",
       "      <td>E09000022</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>67770.98843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Lewisham</td>\n",
       "      <td>E09000023</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>60491.26109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Merton</td>\n",
       "      <td>E09000024</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>82070.61330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Newham</td>\n",
       "      <td>E09000025</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>53539.31919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Redbridge</td>\n",
       "      <td>E09000026</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>72189.58437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Richmond upon Thames</td>\n",
       "      <td>E09000027</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>109326.12450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Southwark</td>\n",
       "      <td>E09000028</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>67885.20344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Sutton</td>\n",
       "      <td>E09000029</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>71536.97357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Tower Hamlets</td>\n",
       "      <td>E09000030</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>59865.18995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Waltham Forest</td>\n",
       "      <td>E09000031</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>61319.44913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Wandsworth</td>\n",
       "      <td>E09000032</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>88559.04381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Westminster</td>\n",
       "      <td>E09000033</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>133025.27720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Inner London</td>\n",
       "      <td>E13000001</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>78251.97650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Outer London</td>\n",
       "      <td>E13000002</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>72958.79836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>NORTH EAST</td>\n",
       "      <td>E12000001</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>42076.35411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>NORTH WEST</td>\n",
       "      <td>E12000002</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>43958.48001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>YORKS &amp; THE HUMBER</td>\n",
       "      <td>E12000003</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>44803.42878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>EAST MIDLANDS</td>\n",
       "      <td>E12000004</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>45544.52227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>WEST MIDLANDS</td>\n",
       "      <td>E12000005</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>48527.52339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>EAST OF ENGLAND</td>\n",
       "      <td>E12000006</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>56701.59610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>LONDON</td>\n",
       "      <td>E12000007</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>74435.76052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>SOUTH EAST</td>\n",
       "      <td>E12000008</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>64018.87894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>SOUTH WEST</td>\n",
       "      <td>E12000009</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>54705.15790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>England</td>\n",
       "      <td>E92000001</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>53202.77128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>City of London</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>1995-02-01</td>\n",
       "      <td>82202.77314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Barking &amp; Dagenham</td>\n",
       "      <td>E09000002</td>\n",
       "      <td>1995-02-01</td>\n",
       "      <td>51085.77983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Barnet</td>\n",
       "      <td>E09000003</td>\n",
       "      <td>1995-02-01</td>\n",
       "      <td>93190.16963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          London_Borough         ID      Month  Average_price\n",
       "0         City of London  E09000001 1995-01-01    91448.98487\n",
       "1     Barking & Dagenham  E09000002 1995-01-01    50460.22660\n",
       "2                 Barnet  E09000003 1995-01-01    93284.51832\n",
       "3                 Bexley  E09000004 1995-01-01    64958.09036\n",
       "4                  Brent  E09000005 1995-01-01    71306.56698\n",
       "5                Bromley  E09000006 1995-01-01    81671.47692\n",
       "6                 Camden  E09000007 1995-01-01   120932.88810\n",
       "7                Croydon  E09000008 1995-01-01    69158.16225\n",
       "8                 Ealing  E09000009 1995-01-01    79885.89069\n",
       "9                Enfield  E09000010 1995-01-01    72514.69096\n",
       "10             Greenwich  E09000011 1995-01-01    62300.10169\n",
       "11               Hackney  E09000012 1995-01-01    61296.52637\n",
       "12  Hammersmith & Fulham  E09000013 1995-01-01   124902.86020\n",
       "13              Haringey  E09000014 1995-01-01    76287.56947\n",
       "14                Harrow  E09000015 1995-01-01    84769.52599\n",
       "15              Havering  E09000016 1995-01-01    68000.13774\n",
       "16            Hillingdon  E09000017 1995-01-01    73834.82964\n",
       "17              Hounslow  E09000018 1995-01-01    72231.70537\n",
       "18             Islington  E09000019 1995-01-01    92516.48557\n",
       "19  Kensington & Chelsea  E09000020 1995-01-01   182694.83260\n",
       "20  Kingston upon Thames  E09000021 1995-01-01    80875.84843\n",
       "21               Lambeth  E09000022 1995-01-01    67770.98843\n",
       "22              Lewisham  E09000023 1995-01-01    60491.26109\n",
       "23                Merton  E09000024 1995-01-01    82070.61330\n",
       "24                Newham  E09000025 1995-01-01    53539.31919\n",
       "25             Redbridge  E09000026 1995-01-01    72189.58437\n",
       "26  Richmond upon Thames  E09000027 1995-01-01   109326.12450\n",
       "27             Southwark  E09000028 1995-01-01    67885.20344\n",
       "28                Sutton  E09000029 1995-01-01    71536.97357\n",
       "29         Tower Hamlets  E09000030 1995-01-01    59865.18995\n",
       "30        Waltham Forest  E09000031 1995-01-01    61319.44913\n",
       "31            Wandsworth  E09000032 1995-01-01    88559.04381\n",
       "32           Westminster  E09000033 1995-01-01   133025.27720\n",
       "34          Inner London  E13000001 1995-01-01    78251.97650\n",
       "35          Outer London  E13000002 1995-01-01    72958.79836\n",
       "37            NORTH EAST  E12000001 1995-01-01    42076.35411\n",
       "38            NORTH WEST  E12000002 1995-01-01    43958.48001\n",
       "39    YORKS & THE HUMBER  E12000003 1995-01-01    44803.42878\n",
       "40         EAST MIDLANDS  E12000004 1995-01-01    45544.52227\n",
       "41         WEST MIDLANDS  E12000005 1995-01-01    48527.52339\n",
       "42       EAST OF ENGLAND  E12000006 1995-01-01    56701.59610\n",
       "43                LONDON  E12000007 1995-01-01    74435.76052\n",
       "44            SOUTH EAST  E12000008 1995-01-01    64018.87894\n",
       "45            SOUTH WEST  E12000009 1995-01-01    54705.15790\n",
       "47               England  E92000001 1995-01-01    53202.77128\n",
       "48        City of London  E09000001 1995-02-01    82202.77314\n",
       "49    Barking & Dagenham  E09000002 1995-02-01    51085.77983\n",
       "50                Barnet  E09000003 1995-02-01    93190.16963"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try your hand at method (1) here: \n",
    "NaNFreeDF1 = clean_properties[clean_properties['Average_price'].notna()]\n",
    "NaNFreeDF1.head(48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EJJnp-AtcAWF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "London_Borough    13635\n",
       "ID                13635\n",
       "Month             13635\n",
       "Average_price     13635\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we do a count on our new DataFrame, we'll see how many rows we have that have complete information: \n",
    "NaNFreeDF1.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "47b-DUF7cAWH"
   },
   "source": [
    "Looks good! \n",
    "\n",
    "For completeness, now use ***dropna()***. ***dropna()*** will drop all null values. \n",
    "\n",
    "Make a new variable called *NaNFreeDF2*, and assign it the result of calling ***dropna()*** on *clean_properties*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NCQd17hfcAWI"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>London_Borough</th>\n",
       "      <th>ID</th>\n",
       "      <th>Month</th>\n",
       "      <th>Average_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>City of London</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>91448.98487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barking &amp; Dagenham</td>\n",
       "      <td>E09000002</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>50460.22660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barnet</td>\n",
       "      <td>E09000003</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>93284.51832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bexley</td>\n",
       "      <td>E09000004</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>64958.09036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brent</td>\n",
       "      <td>E09000005</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>71306.56698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bromley</td>\n",
       "      <td>E09000006</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>81671.47692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Camden</td>\n",
       "      <td>E09000007</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>120932.88810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Croydon</td>\n",
       "      <td>E09000008</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>69158.16225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ealing</td>\n",
       "      <td>E09000009</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>79885.89069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Enfield</td>\n",
       "      <td>E09000010</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>72514.69096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Greenwich</td>\n",
       "      <td>E09000011</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>62300.10169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Hackney</td>\n",
       "      <td>E09000012</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>61296.52637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hammersmith &amp; Fulham</td>\n",
       "      <td>E09000013</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>124902.86020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Haringey</td>\n",
       "      <td>E09000014</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>76287.56947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Harrow</td>\n",
       "      <td>E09000015</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>84769.52599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Havering</td>\n",
       "      <td>E09000016</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>68000.13774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Hillingdon</td>\n",
       "      <td>E09000017</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>73834.82964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Hounslow</td>\n",
       "      <td>E09000018</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>72231.70537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Islington</td>\n",
       "      <td>E09000019</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>92516.48557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Kensington &amp; Chelsea</td>\n",
       "      <td>E09000020</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>182694.83260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Kingston upon Thames</td>\n",
       "      <td>E09000021</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>80875.84843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Lambeth</td>\n",
       "      <td>E09000022</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>67770.98843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Lewisham</td>\n",
       "      <td>E09000023</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>60491.26109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Merton</td>\n",
       "      <td>E09000024</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>82070.61330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Newham</td>\n",
       "      <td>E09000025</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>53539.31919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Redbridge</td>\n",
       "      <td>E09000026</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>72189.58437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Richmond upon Thames</td>\n",
       "      <td>E09000027</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>109326.12450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Southwark</td>\n",
       "      <td>E09000028</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>67885.20344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Sutton</td>\n",
       "      <td>E09000029</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>71536.97357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Tower Hamlets</td>\n",
       "      <td>E09000030</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>59865.18995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Waltham Forest</td>\n",
       "      <td>E09000031</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>61319.44913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Wandsworth</td>\n",
       "      <td>E09000032</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>88559.04381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Westminster</td>\n",
       "      <td>E09000033</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>133025.27720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Inner London</td>\n",
       "      <td>E13000001</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>78251.97650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Outer London</td>\n",
       "      <td>E13000002</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>72958.79836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>NORTH EAST</td>\n",
       "      <td>E12000001</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>42076.35411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>NORTH WEST</td>\n",
       "      <td>E12000002</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>43958.48001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>YORKS &amp; THE HUMBER</td>\n",
       "      <td>E12000003</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>44803.42878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>EAST MIDLANDS</td>\n",
       "      <td>E12000004</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>45544.52227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>WEST MIDLANDS</td>\n",
       "      <td>E12000005</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>48527.52339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>EAST OF ENGLAND</td>\n",
       "      <td>E12000006</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>56701.59610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>LONDON</td>\n",
       "      <td>E12000007</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>74435.76052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>SOUTH EAST</td>\n",
       "      <td>E12000008</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>64018.87894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>SOUTH WEST</td>\n",
       "      <td>E12000009</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>54705.15790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>England</td>\n",
       "      <td>E92000001</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>53202.77128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>City of London</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>1995-02-01</td>\n",
       "      <td>82202.77314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Barking &amp; Dagenham</td>\n",
       "      <td>E09000002</td>\n",
       "      <td>1995-02-01</td>\n",
       "      <td>51085.77983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Barnet</td>\n",
       "      <td>E09000003</td>\n",
       "      <td>1995-02-01</td>\n",
       "      <td>93190.16963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          London_Borough         ID      Month  Average_price\n",
       "0         City of London  E09000001 1995-01-01    91448.98487\n",
       "1     Barking & Dagenham  E09000002 1995-01-01    50460.22660\n",
       "2                 Barnet  E09000003 1995-01-01    93284.51832\n",
       "3                 Bexley  E09000004 1995-01-01    64958.09036\n",
       "4                  Brent  E09000005 1995-01-01    71306.56698\n",
       "5                Bromley  E09000006 1995-01-01    81671.47692\n",
       "6                 Camden  E09000007 1995-01-01   120932.88810\n",
       "7                Croydon  E09000008 1995-01-01    69158.16225\n",
       "8                 Ealing  E09000009 1995-01-01    79885.89069\n",
       "9                Enfield  E09000010 1995-01-01    72514.69096\n",
       "10             Greenwich  E09000011 1995-01-01    62300.10169\n",
       "11               Hackney  E09000012 1995-01-01    61296.52637\n",
       "12  Hammersmith & Fulham  E09000013 1995-01-01   124902.86020\n",
       "13              Haringey  E09000014 1995-01-01    76287.56947\n",
       "14                Harrow  E09000015 1995-01-01    84769.52599\n",
       "15              Havering  E09000016 1995-01-01    68000.13774\n",
       "16            Hillingdon  E09000017 1995-01-01    73834.82964\n",
       "17              Hounslow  E09000018 1995-01-01    72231.70537\n",
       "18             Islington  E09000019 1995-01-01    92516.48557\n",
       "19  Kensington & Chelsea  E09000020 1995-01-01   182694.83260\n",
       "20  Kingston upon Thames  E09000021 1995-01-01    80875.84843\n",
       "21               Lambeth  E09000022 1995-01-01    67770.98843\n",
       "22              Lewisham  E09000023 1995-01-01    60491.26109\n",
       "23                Merton  E09000024 1995-01-01    82070.61330\n",
       "24                Newham  E09000025 1995-01-01    53539.31919\n",
       "25             Redbridge  E09000026 1995-01-01    72189.58437\n",
       "26  Richmond upon Thames  E09000027 1995-01-01   109326.12450\n",
       "27             Southwark  E09000028 1995-01-01    67885.20344\n",
       "28                Sutton  E09000029 1995-01-01    71536.97357\n",
       "29         Tower Hamlets  E09000030 1995-01-01    59865.18995\n",
       "30        Waltham Forest  E09000031 1995-01-01    61319.44913\n",
       "31            Wandsworth  E09000032 1995-01-01    88559.04381\n",
       "32           Westminster  E09000033 1995-01-01   133025.27720\n",
       "34          Inner London  E13000001 1995-01-01    78251.97650\n",
       "35          Outer London  E13000002 1995-01-01    72958.79836\n",
       "37            NORTH EAST  E12000001 1995-01-01    42076.35411\n",
       "38            NORTH WEST  E12000002 1995-01-01    43958.48001\n",
       "39    YORKS & THE HUMBER  E12000003 1995-01-01    44803.42878\n",
       "40         EAST MIDLANDS  E12000004 1995-01-01    45544.52227\n",
       "41         WEST MIDLANDS  E12000005 1995-01-01    48527.52339\n",
       "42       EAST OF ENGLAND  E12000006 1995-01-01    56701.59610\n",
       "43                LONDON  E12000007 1995-01-01    74435.76052\n",
       "44            SOUTH EAST  E12000008 1995-01-01    64018.87894\n",
       "45            SOUTH WEST  E12000009 1995-01-01    54705.15790\n",
       "47               England  E92000001 1995-01-01    53202.77128\n",
       "48        City of London  E09000001 1995-02-01    82202.77314\n",
       "49    Barking & Dagenham  E09000002 1995-02-01    51085.77983\n",
       "50                Barnet  E09000003 1995-02-01    93190.16963"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filtering the data with NaN values\n",
    "NaNFreeDF2 = clean_properties.dropna()\n",
    "NaNFreeDF2.head(48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bTaY4oO5cAWJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "London_Borough    13635\n",
       "ID                13635\n",
       "Month             13635\n",
       "Average_price     13635\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's do a count on this DataFrame object: \n",
    "NaNFreeDF2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P3X4CvA0cAWM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['City of London', 'Barking & Dagenham', 'Barnet', 'Bexley',\n",
       "       'Brent', 'Bromley', 'Camden', 'Croydon', 'Ealing', 'Enfield',\n",
       "       'Greenwich', 'Hackney', 'Hammersmith & Fulham', 'Haringey',\n",
       "       'Harrow', 'Havering', 'Hillingdon', 'Hounslow', 'Islington',\n",
       "       'Kensington & Chelsea', 'Kingston upon Thames', 'Lambeth',\n",
       "       'Lewisham', 'Merton', 'Newham', 'Redbridge',\n",
       "       'Richmond upon Thames', 'Southwark', 'Sutton', 'Tower Hamlets',\n",
       "       'Waltham Forest', 'Wandsworth', 'Westminster', 'Inner London',\n",
       "       'Outer London', 'NORTH EAST', 'NORTH WEST', 'YORKS & THE HUMBER',\n",
       "       'EAST MIDLANDS', 'WEST MIDLANDS', 'EAST OF ENGLAND', 'LONDON',\n",
       "       'SOUTH EAST', 'SOUTH WEST', 'England'], dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NaNFreeDF2['London_Borough'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KVd0KUb8cAWR"
   },
   "source": [
    "Both these methods did the job! Thus, you can pick either resultant DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KFb1y4u-cAWR"
   },
   "outputs": [],
   "source": [
    "# Using the .shape attribute, compare the dimenions of clean_properties, NaNFreeDF1, and NaNFreeDF2: \n",
    "print(clean_properties.)\n",
    "print(_ _ _.shape)\n",
    "print(NaNFreeDF2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R1s7zSOMcAWT"
   },
   "source": [
    "Our suggestions is to pick NaNFreeDF2. \n",
    "\n",
    "Go drop the rest of the invalid 'London Borough' values.\n",
    "\n",
    "An elegant way to do this is to make a list of all those invalid values, then use the *isin()* method, combined with the negation operator *~*, to remove those values. Call this list *nonBoroughs*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZKv_F2zTcAWT"
   },
   "outputs": [],
   "source": [
    "# A list of non-boroughs. \n",
    "nonBoroughs = ['Inner London', 'Outer London', \n",
    "               'NORTH EAST', 'NORTH WEST', 'YORKS & THE HUMBER', \n",
    "               'EAST MIDLANDS', 'WEST MIDLANDS',\n",
    "              'EAST OF ENGLAND', 'LONDON', 'SOUTH EAST', \n",
    "              'SOUTH WEST', 'England']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "htCU6bAlcAWV"
   },
   "source": [
    "Filter *NanFreeDF2* first on the condition that the rows' values for *London_Borough* is *in* the *nonBoroughs* list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A93oUrRJcAWV"
   },
   "outputs": [],
   "source": [
    "# Do this here. \n",
    "NaNFreeDF2[NaNFreeDF2.London_Borough._ _ _(_ _ _)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7dGYKzu5cAWW"
   },
   "source": [
    "Now put the negation operator *~* before the filter statement to get just those rows whose values for *London_Borough* is **not** in the *nonBoroughs* list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QGsHnDUgcAWX"
   },
   "outputs": [],
   "source": [
    "NaNFreeDF2[_ _ _NaNFreeDF2.London_Borough._ _ _(nonBoroughs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XMd2zFW_cAWa"
   },
   "source": [
    "Then just execute the reassignment: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Y9Tm7BVcAWa"
   },
   "outputs": [],
   "source": [
    "_ _ _ = NaNFreeDF2[~NaNFreeDF2._ _ _.isin(nonBoroughs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "91DZpDsxcAWe"
   },
   "outputs": [],
   "source": [
    "NaNFreeDF2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2-P-vXBFcAWg"
   },
   "source": [
    "Make a new variable called simply *df*, which is what data scientists typically call their final-stage DataFrame that's ready for analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6sUjFQ1-cAWh"
   },
   "outputs": [],
   "source": [
    "# Do that here. \n",
    "_ _ _ = NaNFreeDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IGgspjXGcAWi"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h7rvtjQ_cAWk"
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gh-4l57acAWm"
   },
   "source": [
    "#### 2.6. Visualizing the data\n",
    "It'll help to get a visual idea of the price shift occurring in the London boroughs.\n",
    "\n",
    "Restrict your observations to Camden for now.\n",
    "\n",
    "How have housing prices changed since 1995? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-oow_JhLcAWm"
   },
   "outputs": [],
   "source": [
    "# First of all, make a variable called camden_prices, and assign it the result of filtering df on the following condition:\n",
    "# df['London_Borough'] == 'Camden'\n",
    "camden_prices = df[_ _ _['_ _ _'] == 'Camden']\n",
    "\n",
    "# Make a variable called ax. Assign it the result of calling the plot() method, and plugging in the following values as parameters:\n",
    "# kind ='line', x = 'Month', y='Average_price'\n",
    "_ _ _ = camden_prices.plot(_ _ _ ='line', _ _ _ = 'Month', y='_ _ _')\n",
    "\n",
    "# Finally, call the set_ylabel() method on ax, and set that label to the string: 'Price'. \n",
    "ax._ _ _('_ _ _')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "onOBD9CKcAWo"
   },
   "source": [
    "To limit the amount of temporal data-points, it's useful to extract the year from every value in your *Month* column. 300 is more datapoints than we need.\n",
    "\n",
    "To this end, apply a ***lambda function***. The logic  works as follows. You'll:\n",
    "1. look through the `Month` column\n",
    "2. extract the year from each individual value in that column \n",
    "3. store that corresponding year as separate column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rEpQSO0QcAWo"
   },
   "outputs": [],
   "source": [
    "# Try this yourself. \n",
    "df['Year'] = df['Month'].apply(lambda t: t.year)\n",
    "\n",
    "# Call the tail() method on df\n",
    "df._ _ _()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nna5hT-PcAWp"
   },
   "source": [
    "To calculate the mean house price for each year, you first need to **group by** the London_Borough and Year columns.\n",
    "\n",
    "Make a new variable called *dfg*, and assign it the result of calling the ***groupby()*** method on *df*. Plug in the parameters: by=['Borough', 'Year']. Chain ***mean()*** onto your function to get the average of values. \n",
    "\n",
    "We've helped you with this line, it's a little tricky. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U8erRWaccAWq"
   },
   "outputs": [],
   "source": [
    "# Using the function 'groupby' will help you to calculate the mean for each year and for each Borough. \n",
    "## As you can see, the variables Borough and Year are now indices\n",
    "dfg = _ _ _._ _ _(by=['London_Borough', 'Year']).mean()\n",
    "dfg.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UeIsrPVBcAWr"
   },
   "outputs": [],
   "source": [
    "# Let's reset the index for our new DataFrame dfg, and call the head() method on it. \n",
    "dfg = dfg._ _ _()\n",
    "dfg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gsJ0h6i-cAWs"
   },
   "source": [
    "### 3. Modeling\n",
    "Now comes the really exciting stuff. \n",
    "\n",
    "You'll create a function that will calculate a ratio of house prices, that compares the price of a house in 2018 to the price in 1998. \n",
    "\n",
    "Call this function create_price_ratio. \n",
    "\n",
    "You want this function to:\n",
    "\n",
    "1. Take a filter of dfg, specifically where this filter constrains the London_Borough, as an argument. For example, one admissible argument should be: **dfg[dfg['London_Borough']=='Camden']**. \n",
    "\n",
    "2. Get the Average Price for that borough for 1998 and, seperately, for 2018. \n",
    "\n",
    "3. Calculate the ratio of the Average Price for 1998 divided by the Average Price for 2018. \n",
    "\n",
    "4. Return that ratio. \n",
    "\n",
    "Once you've written this function, you'll use it to iterate through all the unique London Boroughs and work out the ratio capturing the difference of house prices between 1998 and 2018.\n",
    "\n",
    "***Hint***: This section should test the skills you acquired in:\n",
    "- Python Data Science Toolbox (Part 1), all modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P2Fx4GnscAWs"
   },
   "outputs": [],
   "source": [
    "# Here's where you should write your function:\n",
    "def _ _ _(d):\n",
    "    y1998 = float(d['Average_price'][d['Year']==1998])\n",
    "    y2018 = float(d['Average_price'][d['Year']==2018])\n",
    "    ratio = [_ _ _/_ _ _]\n",
    "    return ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-L3XXDOfcAWu"
   },
   "outputs": [],
   "source": [
    "#  Test out the function by calling it with the following argument:\n",
    "# dfg[dfg['London_Borough']=='Barking & Dagenham']\n",
    "create_price_ratio(_ _ _[dfg['London_Borough']=='Barking & Dagenham'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4iznOphscAWv"
   },
   "outputs": [],
   "source": [
    "# We want to do this for all of the London Boroughs. \n",
    "# First, let's make an empty dictionary, called final, where we'll store our ratios for each unique London_Borough.\n",
    "final = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vXocw7CccAWw"
   },
   "outputs": [],
   "source": [
    "# Now let's declare a for loop that will iterate through each of the unique elements of the 'London_Borough' column of our DataFrame dfg.\n",
    "# Call the iterator variable 'b'. \n",
    "for _ _ _ in dfg['London_Borough'].unique():\n",
    "    # Let's make our parameter to our create_price_ratio function: i.e., we subset dfg on 'London_Borough' == b. \n",
    "    borough = dfg[dfg['_ _ _'] == _ _ _]\n",
    "    # Make a new entry in the final dictionary whose value's the result of calling create_price_ratio with the argument: borough\n",
    "    final[b] = create_price_ratio(borough)\n",
    "# We use the function and incorporate that into a new key of the dictionary \n",
    "print(final) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WNyHvOG8cAWy"
   },
   "source": [
    "Now you have a dictionary with data about the ratio of average prices for each borough between 1998 and 2018,  but you can make it prettier by converting it to a DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VqkwL6mUcAWy"
   },
   "outputs": [],
   "source": [
    "# Make a variable called df_ratios, and assign it the result of calling the DataFrame method on the dictionary final. \n",
    "_ _ _ = pd.DataFrame(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "padD0pVNcAW0"
   },
   "outputs": [],
   "source": [
    "# Call the head() method on this variable to check it out. \n",
    "df_ratios.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "01lBHJxrcAW2"
   },
   "outputs": [],
   "source": [
    "# All we need to do now is transpose it, and reset the index! \n",
    "df_ratios_T = _ _ _.T\n",
    "df_ratios = df_ratios_T.reset_index()\n",
    "df_ratios.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zqAiWFF5cAW5"
   },
   "outputs": [],
   "source": [
    "# Let's just rename the 'index' column as 'London_Borough', and the '0' column to '2018'.\n",
    "df_ratios._ _ _(columns={'index':'Borough', 0:'2018'}, inplace=True)\n",
    "df_ratios.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Bj_msyacAW6"
   },
   "outputs": [],
   "source": [
    "# Let's sort in descending order and select the top 15 boroughs.\n",
    "# Make a variable called top15, and assign it the result of calling sort_values() on df_ratios. \n",
    "_ _ _ = df_ratios._ _ _(by='2018',ascending=False).head(15)\n",
    "print(top15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dat6ffSNcAW7"
   },
   "outputs": [],
   "source": [
    "# Let's plot the boroughs that have seen the greatest changes in price.\n",
    "# Make a variable called ax. Assign it the result of filtering top15 on 'Borough' and '2018', then calling plot(), with\n",
    "# the parameter kind = 'bar'. \n",
    "_ _ _ = top15[['Borough','_ _ _']].plot(kind='bar')\n",
    "\n",
    "ax.set_xticklabels(top15.Borough)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dh8A7TaAcAW8"
   },
   "source": [
    "### 4. Conclusion\n",
    "Congratulation!  You're done. Excellent work.\n",
    "\n",
    "What can you conclude? Type your conclusions below. \n",
    "\n",
    "We hope you enjoyed this practical project. It should have consolidated your data cleaning and pandas skills by looking at a real-world problem with the kind of dataset you might encounter as a budding data scientist. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Springboard Data Science Career Track Unit 4 Challenge - Tier 2 Complete.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
